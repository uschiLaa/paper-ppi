---
title: Using tours to visually investigate properties of new projection pursuit indexes with application to problems in physics

# to produce blinded version set to 1
blinded: 0

authors: 
- name: Ursula Laa
  address: School of Physics and Astronomy, Monash University
  email: ursula.laa@monash.edu
- name: Dianne Cook
  address: Department of Econometrics and Business Statistics, Monash University
  email: dicook@monash.edu

keywords:
- scagnostics
- statistical graphics
- data visualisation
- exploratory data analysis
- data science 
- guided tour

abstract: |
  Projection pursuit is used to find interesting low-dimensional projections of high-dimensional data by optimizing an index over all possible projections. Most indexes have been developed to detect departure from known distributions, such as normality, or to find separations between known groups. Here, we are interested in finding projections revealing potentially complex bivariate patterns, using new indexes constructed from scagnostics and a maximum information coefficient, with a purpose to detect unusual relationships between model parameters describing physics phenomena. The performance of these indexes is examined with respect to ideal behaviour, using simulated data, and then applied to problems from gravitational wave astronomy. The implementation builds upon the projection pursuit tools available in the R package, tourr, with indexes constructed from code in the R packages, scagnostics, minerva and mbgraphic.

bibliography: bibliography.bib
output: rticles::springer_article
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{xcolor}
  - \usepackage{bm}
---

```{r initial, echo = FALSE, include = FALSE}
library(knitr)
opts_chunk$set(
  warning = FALSE, message = FALSE, echo = FALSE, 
  fig.path = 'figure/', cache.path = 'cache/', fig.align = 'center', 
  fig.show = 'hold', cache = FALSE, external = TRUE, dev = "pdf",
  fig.height = 5, fig.width = 8, out.width = "\\textwidth"
)
opts_knit$set(eval.after = "fig.cap") #so I can use chunck output in the caption
```

# Introduction

<!-- 
Main point of paper:

- Some metrics for exploring high-dimensional data by finding interesting pairs of variables, can be used to find interesting projections, but some have problems. 
- What are the ways to evaluate.
- What adjustments can be done.
- How it can be applied

Organisation of this section:

- Motivation first?
- PP
- Scagnostics
- section needs shortening
-->

The term "projection pursuit" (PP) was coined by @FT74 to describe a procedure for searching high (say $p-$)dimensional data for "interesting" low-dimensional projections ($d=1$ or $2$ usually). The procedure, originally suggested by @kr69, involves defining a criterion function, or index, that measures the "interestingness" of each $d$-dimensional projection of $p$-dimensional data. This criterion function is optimized over the space of all $d$-dimensional projections of $p$-space, searching for both global and local maxima. It is hoped that the resulting solutions reveal low-dimensional structure in the data not found by methods such as principal component analysis. Projection pursuit is primarily used for visualization, with projected data always reported as plots. 

A large number of projection pursuit indexes have been developed, primarily based on departure from normality, which includes clusters, outliers and skewness, and also for finding separations between known groups (e.g. @f87, @hall89 @CBC92, @naito1997, @lckl2005, @AHC02, @CEM:CEM2568, @JS87, @5508437, @PAN2000153, @FER13, @LOPERFIDO201842).  Less work has been done on indexes to find nonlinear dependence between variables, when $d>1$. 

<!-- check Perisic and Posse (2012) and recent paper by Austrian guys -->

The motivation is based on physics applications, to aid the interpretation of model fits on experimental results. A physical model can be considered to be a set of $p$ free parameters, that cannot be measured directly and are determined by fitting a set of $q (p<q)$ experimental observations, for which predictions can be made once the $p$ parameters are estimated. (Note here, that while we may have analytic expressions for the predictions, this is not always the case and we often have to rely on numerical computation.) Different sets of model parameters ($n$) found to be  compatible with the experimental results within a selected level of confidence yield the data to be examined using projection pursuit. A single prediction can be a complicated function of all of the free parameters, and typically $q \in [100,1000]$ and $p \sim 10$. Current practice is to examine pairs of parameters, or combinations produced by intuition or prior knowledge. This begs the question, whether important nonlinear associations are missed because tools to search are not available.

\textcolor{red}{PP can also be used to explore data with many more variables, data that is commonly seen today. For example, [@Cook:2018mvr] explores a 56-dimensional parameter space, by first reducing the number of dimensions to the first six principal components, before applying projection pursuit. There is not a single solution for working with high-dimensional data. PCA was appropriate for this problem because reducing to principal component space removed the linear dependencies but preserved the nonlinear relationships that were interesting to discover. Some projection pursuit indexes incorporation penalty terms to naturally deal with noise dimensions. Having an efficient optimizer can also important with increasing dimensionality, because there are many more dimensions to search.}

To find appropriate projections pursuit indexes, literature on variable selection was examined. With high-dimensional data, even plotting all pairs of variables can lead to too many plots, which is what "scagnostics" (@scag, @WW08) were developed to address by providing metrics from which to select the most interesting variable pairs. There are eight scagnostics, of which three ("convex", "skinny" and "stringy") are used here. The question is whether these can be adapted into projection pursuit indexes, to search for unusual features in two-dimensional projections of high-dimensional data. Recent PhD research by @Grimm2016 explored the behaviour of scagnostics for selecting variables, and proposed two more that have nicer properties, based on smoothing splines and distance correlation. In addition, two more indexes for measuring dependence have been proposed in the machine learning literature, based on information criteria, maximal and total information coefficient (MIC and TIC) [@Reshef1518], with computationally more efficient versions (MIC_e, TIC_e) [@JMLRv1715308]. These are related to original 1D projection pursuit indexes based on entropy (e.g. @huber85, @JS87). This provides seven current indexes for measuring dependence between two variables, and each is available in an R [@rref] package: scagnostics [@HWscagR], mbgraphic [@mbgraphic] and minerva [@minerva]. The projection pursuit guided tour is available in the R package, tourr [@tourr], and provides optimisation routines, and visualization.


This paper investigates the behaviour of these indexes. Section \ref{sec:construct} discusses index construction, and how they fit into the guided tour. Section \ref{sec:investigate} investigates the behaviour of the indexes, explored primarily using tour methods (@As85, @BCAH05, @CBCH94). The new guided tour with these indexes is applied to two examples from gravitational wave astronomy (Section \ref{sec:phys}).

# Projection pursuit index construction and optimization
\label{sec:construct}

A projection pursuit index (PPI) is a scalar function $f$ defined on an $d$-dimensional data set, computed by taking a $d$-dimensional projection of an $n\times p$ data matrix. Typically the definition is such that larger values of $f$ indicate a more interesting distribution of observations, and therefore maximizing $f$ over all possible $d$ dimensional projections of a data set with $p>d$ variables will find the most interesting projections. This section describes the seven indexes that are to be used to explore bivariate association. Some data pre-processing, including standardization, is advisable, prior to optimizing the PPI. 


## Scaling and standardization

Making a plot always involves some choice of scaling. When a scatterplot is made, effectively, albeit under the hood, the data is scaled into a range of $[a, b]$ (often $a=0, b=1$) on both axes to print it on a page or display in a graphics device window. The range deliminates page space within which to draw. The upshot is that the original data scale is standardized to the range and aspect ratio on the display space. It may be that the original range of one variable is $[1, 1000]$ and the other is $[1, 1.6]$ but the display linearly warps this to $[0, 1]$ and $[0, 1]$, say, giving both variables equal visual weight. 

With high dimensional data, and particularly projections, it is also necessary to re-scale the original range, and it is important to pay attention to what is conventional, or possible, and the effects. The PPIs also may require specific scaling for them to be effectively computed. Both of these are addressed here. The common pre-processing include:

- Standardizing each variable, to have mean 0 and variance 1, so that individual variable scales do not affect the result. Different variable scales are examinable without resorting to projection pursuit, so can be handled prior to searching through high dimensions.
- Sphering the high-dimensional data is often done to remove linear dependence. This is typically done using principal component analysis, and using the principal components as the variables passed to PP. If linear dependence is the only structure PP is not needed, and thus this is removed before PP so that the PPIs are not distracted by simple structure.
- Transform single variables to reduce skewness. It is marginal structure, visible in a single variable, which doesn't need a multivariate technique to reveal. Skewed distributions will inadvertently affect the PPIs, distracting the search for dependence. 
- Remove outliers, which may be an iterative process, to discover, identify and delete. Extreme values will likely affect PPI performance. Outliers can be examined on a case by case basis later.
- Possibly remove noise dimensions, which is also likely to be an iterative process. Directions where the distribution is purely noise make optimization of a PPI more difficult. If a variable is suspected to have little structure and relationship with other variables, conducting PP on the subset of variables without them may improve the efficiency of the search.
- Centring and scaling of the projected data, can be helpful visually. If the data has a small amount of non-normal distribution in some directions, the projected data can appear to wander around the plot window during a tour. It doesn't matter what the centre of the projected data is, so centring removes a wandering scatterplot. Less commonly, it may be useful to scale the projected data to standard values, which would be done to remove any linear dependence remaining in the data. 


\begin{table}[htp]
\caption{Summary of notation}
\centering
\begin{tabular}{|l|p{8.2cm}|} \hline
$p$ & be the number of variables in the data. For physics models the observable space is higher dimension, say $q$, and the data examined is the fitted model space, typically less than 10. \\
$d (=2) $ & projection dimension. For studying physics models, typically $d=2$ and this is the focus for the index definition. \\
$n$ & Number of observations, which for the physics models is the number of fitted models being examined and compared. \\
&\\
$\bm{X}_{n\times p} = (\bm{X}_1, ..., \bm{X}_p)$ & $n\times p$-dimensional data matrix, where variables $\bm{X}_j$ may be scaled or standardised, and $\bm{X}$ may be sphered\\
$\bm{Y}_{n\times 2} = (\bm{Y}_1, ..., \bm{Y}_2)$ & projected data matrix. where $Y_j = (\alpha_1 X_1, ..., \alpha_p X_p)$ \\
$\bm{F}_{p\times 2} = (\bm{\alpha}_1, ..., \bm{\alpha}_2)$ & orthonomal projection matrix\\ 
&\\
$H$ & Convex hull \\
$A$ & Alpha hull \\\hline
\end{tabular}
\label{notation}
\end{table}


## New projection pursuit index functions
\label{sec:indexDef}

Table \ref{notation} summarises the notation used for this section. Here we give an overview of the functions that are converted into projection pursuit indexes. Full details of the functions can be found in the original sources. 


* **scagnostics**: The first step to computing the scagnostics is that the bivariate data is binned, and scaled between [0,1] for calculations. The convex and alpha hulls, and the minimal spanning tree (MST), are computed. 
    + *convex*: The ratio of the area of alpha to convex hull, $I_{\bm{F}, convex}= \frac{area(A(Y))}{area(H(Y))}$. This is the only measure where interesting projections will take low values, with a maximum of 1 if both areas are the same. Thus $1-c_{convex}$ is used.
    + *skinny*: The ratio of the perimeter to the area of the alpha hull, $I_{\bm{F}, skinny} = 1 -  \frac{\sqrt{4\pi area(A)}}{perimeter(A)}$, where the normalization is chosen such that $I_{\bm{F}, skinny} = 0$ for a full circle. Values close to 1 indicate a skinny polygon.
    + *stringy*: Based on the MST, $I_{\bm{F}, stringy} = \frac{diameter(MST)}{length(MST)}$ where the diameter is the longest connected path, and the length is the total length (sum of all edges). If the MST contains no branches $I_{\bm{F}, skinny} = 1$.

* **association**: The index functions are available in @mbgraphic, and are defined to range in [0,1]. Both functions in the mbgraphic package can bin the data before computing the index, for computational performance.
    + *dcor2D*: This function is based on distance correlation [@szekely2007], which is designed to find both linear and nonlinear dependencies between variables. It involves computing the distances between pairs of observations, conducting an analysis of variance type breakdown of the distances relative to each variable, and the result is then passed to the usual covariance and hence correlation formula. The function wdcor, in the R package, extracat [@extracat], computes the statistic, and the mbgraphic package utilises this function. 
    + *splines2D*: Measures nonlinear dependence by fitting a spline model of $\bm{Y}_2$ on $\bm{Y}_1$ and also $\bm{Y}_1$ on $\bm{Y}_2$, using the \texttt{gam} function in the R package, mgcv [@w16]. The index compares the variance of the residuals:
    \begin{equation}
    I_{\bm{F}, splines2d} = max(1- \frac{Var(res_{\bm{Y}_1\sim \bm{Y}_2})}{Var(\bm{Y}_1)}, 1-\frac{Var(res_{\bm{Y}_2\sim {\bm{Y}_1}})}{Var(\bm{Y}_2)}),
    \end{equation}
    which takes large values if functional dependence is strong.
    
* **information**:  The index functions [@Reshef1518] nonparametricly measure nonlinear association by computing the mutual information, 
\begin{equation}
\bm{I} = \sum_{by_1}\sum_{by_2} p(by_1, by_2) log(p(by_1, by_2)/(p(by_1)p(by_2))),
\end{equation}
where $by_1, by_2$ are binned values of the projected data, and $p(by_1, by_2)$is the relative bin count in each cell, and $p(by_1), p(by_2)$ are the row and column relative counts, on a range of bin resolutions of the data. It is strictly a 2D measure. For a fixed binning, e.g. $2\times 2$ or $10\times 4$, the optimal binning is found by maximizing $I$. The values of I range between $[0,1]$ because they are normalized across bins by dividing by $log(min(\# bins_{y_1}, \# bins_{y_2}))$.  
    - *Maximum Information Coefficient (MIC)*: uses the maximum normalized $I$ across all bin resolutions. 
    - *Total Information Coefficient (TIC)*: sums the normalized $I$ for all bin resolutions computed. This creates a problem of scaling - there is no upper limit, although it is related to number of bins, and number of bin resolutions used. In the work below we have made empirical estimates of the maximum and scaled the TIC index using this to get it in the range $[0,1]$. This index should be more stable than MIC. 
  
\textcolor{red}{A comparison between these indexes for the purpose of variable selection was discussed in @Grimm2016, and can be summarised as follows. The scagnostics measures are flexible and calculating the full set of measures provides useful guidance in variable selection, however they are found to be highly sensitive to outlying points and sample size (as a consequence of the binning). Both splines2D and dcor2D are found to be robust in this respect, but splines2D is limited to functional dependence, while dcor2D is found to take large values only in scenarios with large linear correlation. Finally the mutual information based index functions are found to be flexible, but are sensitive to the sample size and often take relatively large values also when no association is present. A comparison of MIC and dcor2D was also presented in @2014arXiv1401.7645S.}

\textcolor{red}{In addition to the seven indexes described above, we will also consider the holes index included in the `tourr` package, see [@CBC93,@Cook:2007:IDG:1557227]. This serves as a benchmark, demonstrating the desired behaviour. The index takes maximum values for a central hole distribution, and we rescale the values as described in the appendix such that values close to zero are found for normal distributions.}

## Optimization
Given a PPI we are confronted with the task of finding the maximum over all possible $d$ dimensional projections. One challenge is to avoid getting trapped in local maxima that are only a result of sampling fluctuations or a consequence of a noisy index function. @posse95b discusses the optimization, in particular that for most index functions and optimizers results are too local, largely dependent on starting point. @f87 suggested a two-step procedure: the first step is using a large step size to find the approximate global maximum while stepping over pseudomaxima. A second step is then starting from the projection corresponding to the approximate maximum and employing a gradient directed optimization for the identification of the maximum. For exploring high-dimensional data, it can be interesting to observe local maxima as well as a global maximum, and thus a hybrid algorithm that still allows lingering but not being trapped by local maxima is ideal. In addition, being able to visually monitor the optimisation and see the optimal projection in the context of neighbouring projections is useful. This is provided by combining projection pursuit with the grand tour [@CBCH94]. The properties of a suitable optimization algorithm include monotonicity of the index value, a variable step-size to avoid overshooting and to increase the chance of reaching the nearest maximum, and a stopping criterion allowing to move out of a local maximum and into a new search region [@tourr]. A possible algorithm is inspired by simulated annealing and has been described in @lckl2005, this has been implemented in the \texttt{search\_better} and \texttt{search\_better\_random} search functions in the tourr package. The tourr package also provides the \texttt{search\_geodesic} function, which first selects a promising direction by comparing index values between a selected number of small random steps, and then optimises the function over the line along the geodesic in that direction considering projections up to $\pi/4$ away from the current view.


```{r load}
library(tourr)
library(tidyverse)
library(binostics)
library(gridExtra)
library(tictoc) #timer
library(mbgraphic) #Katrins package
library(GGally)
library(geozoo)
library(minerva) #MINE indices
library(kableExtra)
library(forcats)
```


# Investigation of indexes
\label{sec:investigate}

A useful projection pursuit index needs to have several properties. This has been discussed in several seminal papers, e.g. @diaconis84, @huber85, @JS87, @posse95b, @hall89. The PPI should be  minimized by the normal distribution, because this is not interesting from a data exploration perspective. If all projections are normally distributed, good modelling tools already exist. A PPI should be approximately affine invariant, regardless how the projection is rotated the index value should be the same, and the scale of each variable shouldn't affect the index value. Interestingly the original index proposed by @FT74 was not rotationally invariant. A consistent index means that small perturbations to the sample do not dramatically change the index value. This is particularly important to making optimization feasible, small angles between projections correspond to small perturbations of the sample, and thus should be small changes to index value. @posse95b suggests that indexes should be resistant to features in a tail of the distribution, but this is debatable because one departure from normality that is interesting to detect are anomalous observations. Some PPI are designed precisely for these reasons. Lastly, because we need to compute the PPI over many projections, it needs to be fast to compute. These form the basis of the criteria upon which the scagnostic indexes, and the several alternative indexes are examined, as explained below.

- **smoothness**: This is the consistency property mentioned above. The index function values are examined over interpolated tour paths, that is, the value is plotted against time, where time indexes the sequence of projections produced by the tour path. The signature of a good PPI is that the plotted function is relatively smooth. The interpolation path corresponds to small angle changes between projections, so the value should be very similar. 

- **squintability**: @barnett1981interpreting introduced the idea of squint angle to indicate resolution of structure in the data. Fine structure like the parallel planes in the infamous RANDU data [@Marsaglia68] has a small squint angle because you have to be very close to the optimal projection plane to be able to see the structure. Structures with small squint angle are difficult to find, because the optimization algorithm needs to get very close to begin hill-climbing to the optimum. The analyst doesn't have control over the data structure, but does have control over the PPI. Squintability is about the shape of the PPI over all projections. It should have smooth low values for noise projections and a clearly larger value, ideally with a big squint angle, for structured projections. The optimizer should be able to clearly see the optimal projections as different from noise. To examine squintability, the PPI values are examined on interpolated tour paths between a noise projection and a distant structured projection. 

- **flexibility**: An analyst can have a toolbox of indices that may cover the range of fine and broad structure, which underlies the scagnostics suite. Early indexes, based on density estimation could be programmed to detect fine or large structure by varying the binwidth. This is examined by using a range of structure in the simulated data examples. 

- **rotation invariance**: The orientation of structure within a projection plane should not change the index value. This is especially important when using the projection pursuit guided tour, because the tour path is defined between planes, along a geodesic path, not bases within planes. If a particular orientation is more optimal, this will get lost as the projection shown pays no attention to orientation. @BCAH05 describes alternative interpolation paths based on Givens and Householder rotations which progress from basis to basis. It may be possible to ignore rotation invariance with these interpolations but there isn't a current implementation, primarily because the within-plane spin that is generated is distracting from a visualization perspective. Rotation invariance is checked for the proposed PPIs by rotating the structured projection, within the plane.

- **speed**: Being fast to compute allows the index to be used in real-time in a guided tour, where the optimization can be watched. When the computations are shifted off-line, to watch in replay, computation times matter less. This is checked  by comparing times for benchmark scenarios with varying sample size. 
    
## Simulation study setup

### Data construction
\label{sec:dataOv}

Three families of data simulations are used for examining the behaviour of the index functions. Each generates  structure in two variables, with the remaining variables containing various types of noise. This is a very simple construction, because there is no need for projection pursuit to find the structure, one could simply use the PPIs on pairs of variables. However, it serves the purpose to also evaluate the PPIs. The three data families are explained below. In each set, $n$ is used for the number of points, $p$ is the number of dimensions, and $d=2$ is the projection dimension. 
\textcolor{red}{The three structures were selected to cover both functional and non-functional dependence, different types of nuisance distributions and different structure size and squintability properties.}

- **pipe**: nuisance directions are generated by sampling independently from a uniform distribution between $[-1,1]$, and the circle is generated by sampling randomly on a 2D circle, and adding a small radial noise. The circle should be easy to see by some indices because it is large structure, but the nonlinearity creates a complication. 
- **sine**:  nuisance directions are generated by sampling independently from a standard normal distribution, and the sine curve is generated by $x_p = \sin(x_{p-1}) + \mathrm{jittering}$. The sine is a medium nonlinear structure, which should be visible to multiple indices.
- **spiral**:  nuisance directions are generated by sampling independently from a normal distribution, and the structure directions are sampled from an Archimedean spiral, i.e. $r = a + b \theta$, with $a=b=0.1$ and we sample angles $\theta$ from a normal distribution with mean 0 and variance $2\pi$, giving a spiral with higher densities at lower radii. The absolute value of $\theta$ fixes the direction of the spiral shape. This is fine structure which is only visible close to the optimal projection.

```{r util}
#defining index functions to be used with the tour
scagIndex <- function(scagType){
  function(mat){
    sR <- scagnostics.default(mat[,1],mat[,2])$s
    return(sR[scagType])
  }
}

scagIndexNbin <- function(scagType, n){
  function(mat){
    sR <- scagnostics.default(mat[,1], mat[,2], bins = n)$s
    return(sR[scagType])
  }
}

invConvexIndex <- function(){
  function(mat){
    sR <- scagnostics.default(mat[,1],mat[,2])$s
    return(1 - sR["Convex"])
  }
}

splineIndex <- function(){
  function(mat){
    return(splines2d(mat[,1], mat[,2]))
  }
}

dcorIndex <- function(){
  function(mat){
    return(dcor2d(mat[,1], mat[,2]))
  }
}

mineIndex <- function(mineIndex){
  function(mat){
    return(mine(mat[,1], mat[,2])[[mineIndex]])
  }
}

mineIndexE <- function(mineIndex){
  function(mat){
    return(mine(mat[,1], mat[,2], est = "mic_e")[[mineIndex]])
  }
}

mineIndexAlpha <- function(mineIndex, alpha){
  function(mat){
    return(mine(mat[,1], mat[,2], alpha=alpha)[[mineIndex]])
  }
}

##rescaled holes, cmass
holesR <- function(){
  function(mat){
    ret <- tourr::holes(mat)
    if(ret<0.8) ret <- 0.
    else ret <- (ret-0.8) * 5
    return(ret)
  }
}

cmassR <- function(){
  function(mat){
    ret <- tourr::cmass(mat)
    if(ret<0.2) ret <- 0.
    else ret <- (ret-0.2) * 1.25
    return(ret)
  }
}

rescaleHoles <- function(x){
  if(x<0.8) x <- 0.
  else x <- (x-0.8) * 5
  return(x)
}

rescaleCmass <- function(x){
  if(x<0.2) x <- 0.
  else x <- (x-0.2) * 1.25
  return(x)
}


```


```{r datasetFunctions}
sphereData <- function(n, p){
  dRet <- geozoo::sphere.solid.random(n,p)
  return(as_tibble(dRet$points))
}

pipeData <- function(n, p){
  i <- 1
  dRet <- NULL
  while(i <= p){
    v <- runif(n, -1, 1)
    if(abs(v[n-1]*v[n-1] + v[n]*v[n] - 1) < 0.1){
      dRet <- rbind(dRet, v)
      i <- i+1
    }
  }
  return(as_tibble(dRet))
}

sinData <- function(n, p){
  vName <- paste0("V",n)
  vNameM1 <- paste0("V",n-1)
  expr <- paste0(vName,"=sin(",vNameM1,")") # need string expression if I want to use tibble here
  dRet <- as_tibble(matrix(rnorm((n-1)*p), ncol=(n-1))) #generate normal distributed n-1 dim data
  dRet <- mutate_(dRet, expr) #string evaluation calculates var(n) as tan(var(n-1))
  colnames(dRet)[n] <- vName #correct name of new variable
  dRet[vName] <- jitter(dRet[[vName]]) #adding noise
  return(dRet)
}

spiralData <- function(n, p){
  i <- 1
  a <- 0.1
  b <- 0.1
  dRet <- NULL
  while(i <= p){
    v <- rnorm(n-2)
    theta <- abs(rnorm(1,0,2*pi))
    r <- a + b * theta
    x <- r * cos(theta)
    y <- r * sin(theta)
    v <- c(v, x, y)
    dRet <- rbind(dRet, v)
    i <- i+1
  }
  return(dRet)
}

```

```{r datasets}
# sample(1000:9999, 1)
set.seed(3705)
spiral100 <- spiralData(6, 100) %>% scale() %>% as_tibble()
spiral1000 <- spiralData(6, 1000) %>% scale() %>% as_tibble()
#sphere100 <- sphereData(6, 100) %>% scale() %>% as_tibble()
#sphere1000 <- sphereData(6, 1000) %>% scale() %>% as_tibble()

pipe100 <- pipeData(6, 100) %>% scale() %>% as_tibble()
pipe1000 <- pipeData(6,1000) %>% scale() %>% as_tibble()

sin100 <- sinData(6, 100) %>% scale() %>% as_tibble()
sin1000 <- sinData(6, 1000) %>% scale() %>% as_tibble()
```


```{r data, fig.width=6, fig.height=7, fig.cap="Scatterplots of pairs of variables from samples of each family, showing the nuisance variables and structured variables.", out.width = "0.8\\textwidth"}
dsn <- spiral1000 %>% select(V1, V2) %>%
  rename(X1=V1, X2=V2) %>%
  mutate(family="spiral", type="nuisance")
dss <- spiral1000 %>% select(V5, V6) %>%
  rename(X1=V5, X2=V6) %>%
  mutate(family="spiral", type="structured")
dpn <- pipe1000 %>% select(V1, V2) %>%
  rename(X1=V1, X2=V2) %>%
  mutate(family="pipe", type="nuisance")
dps <- pipe1000 %>% select(V5, V6) %>%
  rename(X1=V5, X2=V6) %>%
  mutate(family="pipe", type="structured")
din <- sin1000 %>% select(V1, V2) %>%
  rename(X1=V1, X2=V2) %>%
  mutate(family="sine", type="nuisance")
dis <- sin1000 %>% select(V5, V6) %>%
  rename(X1=V5, X2=V6) %>%
  mutate(family="sine", type="structured")
d <- bind_rows(dsn, dss, dpn, dps, din, dis)
ggplot(d, aes(x=X1, y=X2)) + geom_point(alpha=0.3) + 
  facet_grid(type~family) + theme(aspect.ratio=1) +
  xlab("") + ylab("")
```

```{r indexTable, echo=FALSE}
tableTemp <- function(){
  tibble(
    index=character(),
    data=character(),
    size=numeric(),
    type=character(),
    value5=numeric(),
    value95=numeric()
  )
}

getSample <- function(dataT, size){
  if (dataT == "Pipe"){
    ret <- pipeData(p = size, n = 6) %>% scale() %>% as_tibble()
  }
  if (dataT == "Spiral"){
    ret <- spiralData(p = size, n = 6) %>% scale() %>% as_tibble()
  }
  if (dataT == "Sine"){
    ret <- sinData(p = size, n = 6) %>% scale() %>% as_tibble()
  }
  return(ret)
}

getIdx <- function(dataT, size, type){
  convex <- numeric(length = 100)
  skinny <- numeric(length = 100)
  stringy <- numeric(length = 100)
  micidx <- numeric(length = 100)
  ticidx <- numeric(length = 100)
  dcor2D <- numeric(length = 100)
  splines2D <- numeric(length = 100)
  holesI <- numeric(length = 100)
  for(i in 1:100){
    cSample <- getSample(dataT, size)
    if(type == "noise"){
      x = as.numeric(cSample$V1)
      y = as.numeric(cSample$V2)
    } else{
      x = as.numeric(cSample$V5)
      y = as.numeric(cSample$V6)
    }
    scag <- scagnostics(x=x, y=y)$s
    midx <- mine(x, y, est = "mic_e")
    skinny[i] <- scag["Skinny"]
    stringy[i] <- scag["Stringy"]
    convex[i] <- scag["Convex"]
    micidx[i] <- midx$MIC
    if (size == 100) {ticidx[i] <- midx$TIC / 16}
    if (size == 1000) {ticidx[i] <- midx$TIC / 148}
    dcor2D[i] <- dcor2d(x=x, y=y)
    splines2D[i] <- splines2d(x,y)
    holesI[i] <- holes(matrix(c(x,y), ncol = 2))
    
  }
  #sortedList <- lapply(list(skinny, stringy, convex, micidx, ticidx, dcor2D, splines2D, holesI), sort)
  skinny <- sort(skinny)
  stringy <- sort(stringy)
  convex <- sort(convex)
  micidx <- sort(micidx)
  ticidx <- sort(ticidx)
  dcor2D <- sort(dcor2D)
  splines2D <- sort(splines2D)
  holesI <- sort(holesI)
  res <- tableTemp() %>%
    add_row(index="skinny", data=dataT, size=size,
            type=type,
            value5=skinny[5], value95=skinny[95]) %>%
    add_row(index="stringy", data=dataT, size=size,
            type=type,
            value5=stringy[5], value95=stringy[95]) %>%
    add_row(index="convex", data=dataT, size=size,
            type=type,
            value5=convex[5], value95=convex[95]) %>%
    add_row(index="MICe", data=dataT, size=size,
            type=type,
            value5=micidx[5], value95=micidx[95]) %>%
    add_row(index="TICe", data=dataT, size=size,
            type=type,
            value5=ticidx[5], value95=ticidx[95]) %>%
    add_row(index="dcor2D", data=dataT, size=size,
            type=type,
            value5=dcor2D[5], value95=dcor2D[95]) %>%
    add_row(index="splines2D", data=dataT, size=size,
            type=type,
            value5=splines2D[5], value95=splines2D[95]) %>%
    add_row(index="holes", data=dataT, size=size,
            type=type,
            value5=holesI[5], value95=holesI[95])
}

if(!file.exists("cache/indexTable.rda")){
  set.seed(505)
  res <- tableTemp()
  for(ds in c("Pipe", "Sine", "Spiral")){
    for (size in c(100, 1000)){
      for (type in c("structure", "noise")){
        res <- bind_rows(res,getIdx(ds, size, type))
      }
    }
  }
  res <- res %>% arrange(data, size, index, type) %>% select(data, size, index, type, value5, value95)
  save(res, file = "cache/indexTable.rda")
} else {
  load("cache/indexTable.rda")
}
#rescale holes index first
res <- res %>%
  rowwise() %>%
  mutate(value5 = if_else(index=="holes", rescaleHoles(value5), value5)) %>%
  rowwise() %>%
  mutate(value95 = if_else(index=="holes", rescaleHoles(value95), value95))
resp <- res %>% filter(size == 1000, data == "Pipe") %>%
  select(index, type, value5, value95) %>%
  rename(lower=value5, upper=value95)
resi <- res %>% filter(size == 1000, data == "Sine") %>%
  select(index, type, value5, value95) %>%
  rename(lower=value5, upper=value95)
ress <- res %>% filter(size == 1000, data == "Spiral") %>%
  select(index, type, value5, value95) %>%
  rename(lower=value5, upper=value95)
res_all <- bind_cols(resp, resi, ress) %>%
  select(-index1, -type1, -index2, -type2) %>%
  mutate(indexF = factor(index, c("holes", "convex", "skinny", "stringy", "dcor2D", "splines2D", "MICe", "TICe"))) %>%
  arrange(indexF) %>%
  select(-indexF, -index) %>%
  add_column(index = c("holes", "", "convex", "", "skinny", "", "stringy", "", "dcor2D", "", "splines2D", "", "MICe", "", "TICe", ""))
# Good resource for doing tables
# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
kable(res_all, format = "latex",  caption = "Comparison of index values between noise projections and structured projections for sample size 1000, using 5th and 95th percentiles from 100 simulated sets. Most indices have much larger values for the structured projections, except for convex.", 
      col.names=c("Index","", "lower", "upper", "lower", "upper", "lower", "upper"),
      digits=2, booktabs = T) %>% 
      add_header_above(c(" ", " ", "pipe" = 2, "sine" = 2, "spiral"=2)) %>%
  group_rows("", 1, 2, latex_gap_space = "-0.2cm") %>%
  group_rows("", 3, 4, latex_gap_space = "-0.2cm") %>%
  group_rows("", 5, 6, latex_gap_space = "-0.2cm") %>%
  group_rows("", 7, 8, latex_gap_space = "-0.2cm") %>%
  group_rows("", 9, 10, latex_gap_space = "-0.2cm") %>%
  group_rows("", 11, 12, latex_gap_space = "-0.2cm") %>%
  group_rows("", 13, 14, latex_gap_space = "-0.2cm") %>%
  group_rows("", 15, 16, latex_gap_space = "-0.2cm") %>% 
  #row_spec(1:16, font_size = 10) %>%
  kable_styling(position = "center") #, font_size = 7) 
```


\textcolor{red}{For simplicity in the investigations of the index behaviour, we fix $p=6$, which corresponds two independent 2D planes containing nuisance distributions, and one 2D plane containing the structured distribution. }
The structured projection is in variables 5 and 6 ($x_5, x_6$). Two samples sizes are used: $n=(100, 1000)$. All variables are standardized to have mean 0 and standard deviation 1. Figure \ref{fig:data} shows samples from each of the families, of the nuisance and structured pairs of variables. Table \ref{tab:indexTable} compares the PPIs for structured projections against those for nuisance variables, based on 100 simulated data sets of each type, using sample size 1000. The lower and upper show the 5th and 95th percentile of values. The holes index is sensitive only to the pipe distribution. All other indexes, except convex show distinctly higher values for the structured projections. The convex index shows the inverse scale to other indices, thus (1-convex) will be used in the assessment of performance of PPIs. The scale for the holes index in its original implementation is smaller than the others ranging from about 0.7 through 1, so it is re-scaled in the performance assessment so that all indices can be plotted on a common scale of 0-1 (details in Appendix). Similarly, the TIC index is re-scaled depending on sample size. 

### Property assessment {#sec:propAss}

The procedures for assessing the PPI properties of smoothness, squintability, flexibility, rotation invariance, and speed examined for samples from the family of data sets are:


1. Compute the PPI values on the tour path along an interpolation between pairs of nuisance variables, $x_1 - x_2$ to $x_3 - x_4$. The result is ideally a smooth change in low values. This checks the smoothness property. 
2. Change to a tour path between a pair of nuisance variables $x_1 - x_2$ and the structured pair of variables $x_5 - x_6$ via the intermediate projection onto $x_1 - x_5$, and compute the PPI along this. This examines the squintability, and smoothness. If the function is smooth and slowly increases towards the structured projection, then the structure is visible from a distance. 
3. Use the guided tour to examine the ease of optimization. This depends on having a relatively smooth function, with structure visible from a distance. One index is optimized to show how effectively the maximum is attained, and the values for other PPIs is examined along the same path, to examine the similarity between PPIs. 
4. Rotation invariance is checked by computing PPIs on rotations of the structured projection. 
5. Computational speed for the selected indexes is examined on a range of sample sizes.



```{r dataPlotsV1V2, fig.width=6, fig.height=7, fig.cap="Projection of all data sets considered onto the first two parameters $x_1$ and $x_2$, i.e. showing a typical uninformed view for each dataset.", eval=FALSE}
pL <- list()
i <- 1
pLabels <- c("Spiral 100", "Spiral 1000", "Pipe 100", "Pipe 1000", "Sine 100", "Sine 1000")
for(ds in list(spiral100, spiral1000, pipe100, pipe1000, sin100, sin1000)){
  pC <- ggplot(ds, aes(V1, V2)) +
    geom_point() +
    ggtitle(pLabels[i]) + theme(aspect.ratio=1)
  pL[[i]] <- pC
  i <- i+1
}
grid.arrange(pL[[1]], pL[[2]], pL[[3]], pL[[4]], pL[[5]], pL[[6]],
             ncol=2)
```


```{r dataPlotsV5V6, fig.width=6, fig.height=7, fig.cap="Projection of all data sets considered onto the last two parameters $x_5$ and $x_6$, i.e. showing the special view built into the datasets.", eval=FALSE}
pL <- list()
i <- 1
pLabels <- c("Spiral 100", "Spiral 1000", "Pipe 100", "Pipe 1000", "Sine 100", "Sine 1000")
for(ds in list(spiral100, spiral1000, pipe100, pipe1000, sin100, sin1000)){
  pC <- ggplot(ds, aes(V5, V6)) +
    geom_point() +
    ggtitle(pLabels[i]) + theme(aspect.ratio=1)
  pL[[i]] <- pC
  i <- i+1
}
grid.arrange(pL[[1]], pL[[2]], pL[[3]], pL[[4]], pL[[5]], pL[[6]],
             ncol=2)
```


```{r dataPlotsDensity, fig.width=6, fig.height=7, fig.cap="One dimensional density distribution for all parameters and all data sets considered. Apart from statistical fluctuations we see that for the Pipe datasets the parameters $x_5$ and $x_6$ are pushed towards more extreme values by vetoing points away from the circle outline, and for the Sine (and Spiral) dataset the parameter $x_6$ (and $x_5$) follows a very distinct distribution.", eval=FALSE}
pL <- list()
i <- 1
pLabels <- c("Spiral 100", "Spiral 1000", "Pipe 100", "Pipe 1000", "Sine 100", "Sine 1000")
for(ds in list(spiral100, spiral1000, pipe100, pipe1000, sin100, sin1000)){
  distData <- gather(ds, variable, value)
  pC <- ggplot(distData, aes(value, color=variable)) +
    geom_density() +
    ggtitle(pLabels[i])
  pL[[i]] <- pC
  i <- i+1
}
grid.arrange(pL[[1]], pL[[2]], pL[[3]], pL[[4]], pL[[5]], pL[[6]],
             ncol=2)
```



## PPI traces over a tour sequence of interpolated nuisance projections
\label{sec:smooth}

Figure \ref{fig:plotV1V2toV3V4} shows the traces representing the index values calculated across a tour between a pair of nuisance projections.
\textcolor{red}{The tour path is generating by interpolating between the two independent nuisance planes, i.e. from the projection onto $x_1$-$x_2$ to one onto $x_3$-$x_4$.}
The range of each axis is set to be the limits of the index, as might be expected over many different data sets, 0 to 1. Each projection in the interpolation will also be noise. Two different sample sizes are show, $n=100$ as a dashed line, and $n=1000$ as a solid line. The ideal trace is a smooth function, with relatively low values, and no difference between the sample sizes. A major feature to notice is that the scagnostics produce noisy functions, which is problematic, because small changes in the projection result in big jumps in the value. This will make them difficult to optimize. On the other hand holes, dcor2d, splines2d, MIC and TIC are relatively smooth functions. 

Several of the indexes are sensitive to sample size also, the same structured projection with differing numbers of points, produces different values. 


```{r getProj}
getProj <- function(df, tPath, nameStr, size){
  sc <- tibble(
    holes=numeric(),
    cmass=numeric(),
    convex=numeric(),
    skinny=numeric(),
    stringy=numeric(),
    dcor2d=numeric(),
    splines2d=numeric(),
    MIC=numeric(),
    TIC1=numeric(),
    t=numeric(),
    name=character(),
    size=numeric())
  n <- length(tPath)
  for (i in 1:n) {
    dprj <- as.matrix(df) %*% tPath[[i]]
    scagRes <- scagnostics(dprj)
    dcorRes <- dcor2d(dprj[,1], dprj[,2])
    splineRes <- splines2d(dprj[,1], dprj[,2])
    mineRes <- mine(dprj[,1], dprj[,2])
    holesRes <- holes(dprj)
    cmassRes <- cmass(dprj)
    sc <- add_row(sc, holes=holesRes, cmass=cmassRes,
                  convex=scagRes[,"Convex"], skinny=scagRes[,"Skinny"],
                  stringy=scagRes[,"Stringy"], dcor2d=dcorRes,
                  splines2d=splineRes, MIC=mineRes$MIC,
                  TIC1=mineRes$TIC, t=i, name=nameStr, size=size)
  }
  if (size == 100) {maxTIC <- 16}
  if (size == 1000) {maxTIC <- 148}
  sc <- sc %>%
    mutate(TIC = TIC1/maxTIC) %>%
    select(-TIC1)
  return(sc)
}
```

```{r V1V2toV3V4}
if(!file.exists("cache/V1V2toV3V4.rda")){
  m1 <- matrix(c(1,0,0,0,0,0,0,1,0,0,0,0),ncol=2)
  m2 <- matrix(c(0,0,1,0,0,0,0,0,0,1,0,0),ncol=2)
  #this is silly but seems that first two entries are being ignored, so need some fake entries
  m3 <- matrix(c(1,0,0,0,1,0,0,1,0,0,0,1),ncol=2)
  m4 <- matrix(c(1,1,1,0,0,0,0,1,1,0,0,0),ncol=2)
  t1 <- save_history(sin100,tour_path=planned_tour(list(m3,m4,m1,m2)))
  t1full <- as.list(interpolate(t1))
  fullRes <- getProj(sin100, t1full, "sin", 100) %>%
    rbind(getProj(sin1000, t1full, "sin", 1000)) %>%
    rbind(getProj(spiral100, t1full, "spiral", 100)) %>%
    rbind(getProj(spiral1000, t1full, "spiral", 1000)) %>%
    rbind(getProj(pipe100, t1full, "pipe", 100)) %>%
    rbind(getProj(pipe1000, t1full, "pipe", 1000))
  save(t1, t1full, fullRes, file = "cache/V1V2toV3V4.rda")
} else {
  load("cache/V1V2toV3V4.rda")
}
```

```{r plotV1V2toV3V4, fig.width=6, fig.height=7, fig.cap="PPIs for projections along an interpolation between two nuisance projections. All projections would be nuisance so the PPI are ideally low and smooth, with little difference between sample sizes (solid lines: $n=1000$; dashed: $n=100$). The scagnostic PPIs are noisy. Some indexes have distinct differences in values between sample sizes."}
namesFixed <- str_replace_all(fullRes$name, "sin", "sine")
fullResMelt <- fullRes %>%
  mutate(name = namesFixed) %>%
  mutate(convex = 1-convex) %>%
  rename("1-convex"=convex) %>%
  rowwise() %>%
  mutate(holes = rescaleHoles(holes)) %>%
  gather(PPI, value, -t, -name, -size) %>%
  filter(PPI != "cmass") %>%
  mutate(PPI = fct_relevel(PPI, "holes", "cmass", "1-convex", "skinny", "stringy", "dcor2d", "splines2d", "MIC", "TIC"))

fullResMelt %>% 
  ggplot(aes(x=t, y=value)) + 
  geom_line(aes(group=size, linetype=factor(size, levels=c("1000", "100")))) + 
  ylim(c(0,1)) +
  facet_grid(PPI~name) + 
  theme(legend.position="none") + xlab("Sequence of projections (t)") + ylab("PPI value")
```


## PPI traces over a tour sequence between nuisance and structured projections
\label{sec:squintability}

Figure \ref{fig:wIntermediate} shows the PPIs for a tour sequence between a nuisance and structured projection. A long sequence is generated where the path 
\textcolor{red}{interpolates between projections onto}
$x_1$-$x_2$, $x_1$-$x_5$, $x_5$-$x_6$, in order to see some of the intricacies of holes index. Sample size is indicated by line type: dashed being $n=100$ and solid is $n=1000$. The beginning of the sequence is the nuisance projection and the end is the structured projection. The index values for most PPIs increases substantially nearing the structured projection, indicating that they "see" the structure. Some indexes see all three structures: scagnostics, MIC and TIC,  which means that they are flexible indexes capable of detecting a range of structure. [@Grimm2016]'s indexes, dcor2d and splines2d, are excellent for detecting the sine, and they can see it from far away, indicated by the long slow increase in index value. The holes index easily detects the pipe, and can see it from a distance, but also has local maxima along the tour path. The scagnostic index, stringy, can see the structure but is myopic, only when it is very close. Interestingly the scagnostic, skinny, sees the spiral from a distance.


```{r wIntermediatePath}
if(!file.exists("cache/wIntermediate.rda")){
  m1 <- matrix(c(1,0,0,0,0,0,0,1,0,0,0,0),ncol=2)
  mInt <- matrix(c(1,0,0,0,0,0,0,0,0,0,1,0),ncol=2)
  m2 <- matrix(c(0,0,0,0,1,0,0,0,0,0,0,1),ncol=2)
  #this is silly but seems that first two entries are being ignored, so need some fake entries
  m3 <- matrix(c(1,0,0,0,1,0,0,1,0,0,0,1),ncol=2)
  m4 <- matrix(c(1,1,1,0,0,0,0,1,1,0,0,0),ncol=2)
  t3 <- save_history(sin100,tour_path=planned_tour(list(m3,m4,m1,mInt,m2)))
  t3full <- as.list(interpolate(t3))
  fullResPlanned <- getProj(sin100, t3full, "sin", 100) %>%
    rbind(getProj(sin1000, t3full, "sin", 1000)) %>%
    rbind(getProj(spiral100, t3full, "spiral", 100)) %>%
    rbind(getProj(spiral1000, t3full, "spiral", 1000)) %>%
    rbind(getProj(pipe100, t3full, "pipe", 100)) %>%
    rbind(getProj(pipe1000, t3full, "pipe", 1000))
  save(t3, t3full, fullResPlanned, file = "cache/wIntermediate.rda")
} else {
  load("cache/wIntermediate.rda")
}
```

```{r wIntermediate, fig.width=6, fig.height=7, fig.cap="PPIs for projections along an interpolation between nuisance and structured projections, following $x_1$-$x_2$ to $x_1$-$x_5$ to $x_5$-$x_6$ (solid lines: $n=1000$; dashed: $n=100$). The vertical blue line indicates the position of the projection onto $x_1$-$x_5$ in the sequence. Peaks at the end of the sequence indicate the index sees the structure. The scagnostics, MIC and TIC see all three structures, so are more flexible for general pattern detection. Holes only responds to the pipe, and is a multimodal function for this data with a local maximum at $x_1$-$x_5$. "}
intermediatePlane <- which(attributes(interpolate(t3))$new_basis)[2]
namesFixed <- str_replace_all(fullResPlanned$name, "sin", "sine")
fullResMeltPlanned <- fullResPlanned %>%
  mutate(name = namesFixed) %>%
  mutate(convex = 1-convex) %>%
  rename("1-convex"=convex) %>%
  rowwise() %>%
  mutate(holes = rescaleHoles(holes)) %>%
  gather(PPI, value, -t, -name, -size) %>%
  filter(PPI != "cmass") %>%
  mutate(PPI = fct_relevel(PPI, "holes", "1-convex", "skinny", "stringy", "dcor2d", "splines2d", "MIC", "TIC"))
fullResMeltPlanned %>% 
  ggplot(aes(x=t, y=value)) + 
  geom_line(aes(group=size, linetype=factor(size, levels=c("1000", "100")))) + 
  ylim(c(0,1)) +
  geom_vline(xintercept=intermediatePlane, color="blue", alpha=0.3) +
  facet_grid(PPI~name) + 
  theme(legend.position="none") + xlab("Sequence of projections (t)") + ylab("PPI value")
```


## Optimisation check with the guided tour
\label{sec:guided}


The guided tour combines optimization with interpolation between pairs of planes. Target planes of the path are chosen to maximize the PPI. There are three derivative-free optimization methods available in the guided tour: \verb# search_better_random# (1), \verb# search_better# (2), and \verb# search_geodesic# (3). Method 1 casts a wide net randomly generating projection planes, computing the PPIs and keeping the best projection, and method 2 conducts a localized maximum search. Method 3 is quite different: a local search is conducted to determine a promising direction, and then this direction is followed until the maximum in that direction is found. For all methods the optimization is iterative, the best projections form target planes in the tour, the tour path is the interpolation to this target, and then a new search for a better projection is made, followed by the interpolation. For each projection during the interpolation steps, the PPI is recorded. 

The stopping rule is that no better projections are found after a fixed number of tries, given a fixed tolerance value measuring difference. For method 1 and 2 two additional parameters control the optimization: the search window $\alpha$, giving the maximum distance from the current plane in which projections are sampled, and the cooling factor, giving the incremental decrease in search window size. Method 3 in principle also has two free parameters, which are however fixed in the current implementation. The first is the small step size used when evaluating the most promising direction, it is fixed to 0.01, and the second parameter being the window over which the line search is performed, fixed to $\pm \pi/4$ away from the current plane.

For distributions and indexes with smooth behaviour and good squintability, method 3 is the most effective method for optimization. If these two criteria are not met the method may still be useful, but only given an informed starting projection. In such cases we can follow a method similar to that proposed by Friedman [@f87]: we break the optimization in two distinct steps. A first step ("scouting") uses method 2 with large search window and no cooling as a way of stepping over fluctuations and local maxima and yielding an approximation of the global maximum. Note that this likely requires large number of tries, especially as dimension increases, since most randomly picked planes will not be interesting. The second step uses method 3 starting from the approximate maximum, which will take small steps to refine the result to be closer to the global maximum.


### Looking down the pipe

Despite the simple structure, the pipe is relatively difficult for the PPIs to find. For the TIC index, there is a fairly small squint angle. For the holes index, there are several local maxima, that divert the optimizer. There is a hint of this from Figure \ref{fig:wIntermediate} because the initial projection (left side of trace) of purely noise variables has a higher index value than the linear combinations of noise and structured variables along the path. The uniform distribution was used to generate the noise variables, which has a higher PPI value than a normal distribution, yielding the higher initial value. In addition, a local maximum is observed whenever the pair of variables is one structured variable and one noise variable, because there is a lighter density in the centre of the projection.

The optimization is done in two stages, a scouting phase using method 2, and a refinement stage using method 3.  For the scouting we use $\alpha = 0.5$ and stopping condition of maximum 5000 tries, and we optimised the TIC index.

Figure \ref{fig:pipeFirstRun} shows the target projections (points)  selected during the scouting with method 2 on the TIC index. The focus is on the target projections rather than the interpolation between them, because the optimization is done off-line, and only the targets are used for the next step. The horizontal distance between the points in the plot reflects the relative geodesic distance between the planes in the 6D space. All of the other indexes are shown for interest. The TIC index value is generally low for this data, although it successfully detects the pipe. The holes, convex, skinny, and to some extent MIC, mirror the TIC performance. The holes differs in that it has some intermediate high values which are likely the indication of multi-modality of this index on this data.

The final views obtained in each of the two stages are compared in the Appendix, see Fig. \ref{fig:testpipe}.

```{r findpipe, results="hide"}
if(!file.exists("cache/findpipe.rda")){
  set.seed(1984)
  pipeResc <- as.matrix(pipe1000) 
  pipeTour <- save_history(pipeResc,
                          guided_tour(mineIndex("TIC"), search_f = tourr:::search_better,
                                     cooling=1, alpha = 0.5, max.tries = 5000))
  pipeTourFull <- as.list(interpolate(pipeTour))
  save(pipeResc, pipeTour, pipeTourFull, file = "cache/findpipe.rda")
} else {
  load("cache/findpipe.rda")
}
```

```{r eval=FALSE}
# Quick glimpse of optimisations
myholes <- function(mat) {
    n <- nrow(mat)
    d <- ncol(mat)
    num <- 1 - 1/n * sum(exp(-0.5 * rowSums(mat^2)))
    den <- 1 - exp(-d/2)
    (num/den - 0.7) * 1.43
}
quartz()
set.seed(sample(10000:50000, 1))
animate_xy(pipeResc, guided_tour(scagIndex("Skinny"), search_f = tourr:::search_better, cooling=0.9, alpha = pi, max.tries = 500))
animate_xy(pipeResc, guided_tour(mineIndex("MIC"), search_f = tourr:::search_better, cooling=1, alpha = pi, max.tries = 500))
animate_xy(pipeResc, guided_tour(mineIndex("TIC"), search_f = tourr:::search_better, cooling=1, alpha = pi, max.tries = 5000))
animate_xy(pipeResc, guided_tour(holes, search_f = tourr:::search_geodesic,
      cooling=0.8, alpha = pi, max.tries = 500))
```

```{r pipeFirstRun, fig.width=7, fig.height=7, out.width = "0.8\\textwidth", fig.cap="Scouting for the pipe using optimization method 2 on the TIC index, other PPI values also shown for interest. Only the values for the target planes are shown. Despite the small maximum value of TIC for this data, it identifies the pipe."}
if(!file.exists("cache/pipeFirstRun.rda")){
  pipeTourRes <- getProj(pipe1000, pipeTourFull, "Pipe", 1000)
  #pipeTourResMelt <- melt(pipeTourRes, id=c("t", "name", "size"))
  #never used?
  #save(pipeTourRes, pipeTourResMelt, file = "cache/pipeFirstRun.rda")
  save(pipeTourRes, file = "cache/pipeFirstRun.rda")
} else {
  load("cache/pipeFirstRun.rda")
}
newBasisPipeTour <- pipeTourRes %>%
  mutate(convex = 1-convex) %>%
  rename("1-convex"=convex) %>%
  rowwise() %>%
  mutate(holes = rescaleHoles(holes)) %>%
  select(-cmass) %>%
  gather(variable, value, -t, -name, -size) %>%
  filter(t %in% which(attributes(interpolate(pipeTour))$new_basis)) %>%
  mutate(variable = fct_relevel(variable, "holes", "1-convex", "skinny", "stringy", "dcor2d", "splines2d", "MIC", "TIC"))

ggplot(newBasisPipeTour, aes(x=t, y=value)) +
  geom_point(mapping=aes(color=(variable=="TIC"))) + 
  geom_line(mapping=aes(color=(variable=="TIC"))) + 
  scale_colour_manual(values = c("black", "red")) +
  facet_wrap(~variable, ncol=1, strip.position = "right") +
  guides(color=FALSE) +
  ylim(c(0,1)) +
  xlab("Number of projections") +
  ylab("PPI value") 
```


```{r refinepipe, results="hide"}
if(!file.exists("cache/refinepipe.rda")){
  iLast <- length(pipeTourFull)
  fProj <- pipeTourFull[[iLast]]
  pipeTour2 <- save_history(pipeResc, guided_tour(mineIndex("TIC")), start = fProj)
  pipeTourFull2 <- as.list(interpolate(pipeTour2))
  pipeTourRes2 <- getProj(pipe1000, pipeTourFull2, "Pipe", 1000)
  #pipeTourResMelt2 <- melt(pipeTourRes2, id=c("t", "name", "size"))
  #save(pipeTour2, pipeTourFull2, pipeTourRes2, pipeTourResMelt2, file = "cache/refinepipe.rda")
  save(pipeTour2, pipeTourFull2, pipeTourRes2, file = "cache/refinepipe.rda")
} else {
  load("cache/refinepipe.rda")
}
```



### Finding sine waves

Given the patterns in Figure \ref{fig:wIntermediate} it would be expected that the sine could be found easily, using only optimization method 3 with the splines2d, dcor2d, MIC or TIC indexes. This is examined in Figure \ref{fig:findsine}. Optimization is conducted using the splines2d index, and the trace of the PPI over the optimisation is shown, along with the PPI values for the other indexes over that path. The vertical blue lines indicate anchor bases, where the optimizer stops, and does a new search. The distance between anchor planes is smaller as the maximum is neared.

The only complications arise from a lack of rotation invariance of the splines2d index. It is not easily visible here, but it is possible that the best projection will have a higher PPI. The index changes depending on the basis used to define the plane, but the geodesic interpolation conducted by the tour uses any suitable basis to describe the plane, ignoring that which optimizes the PPI. This is discussed in section \ref{sec:rot}.


```{r findsine, fig.width=6, fig.height=7, out.width = "0.8\\textwidth", fig.cap="Guided tour optimising  the splines2d index, using method 3, for the sine data, with $n=1000$. Anchor planes are marked by the blue vertical lines, and are closer to each other approaching the maxima. The sine is found relatively easily, by splines2d, and it is indicated that MIC, TIC, dcor2d and convex would also likely find this structure.", results="hide"}
set.seed(2018)
if(!file.exists("cache/findsine.rda")){
  sineResc <- as.matrix(sin1000)
  sineTour <- save_history(sineResc,
                          guided_tour(splineIndex()))
  sineTourFull <- as.list(interpolate(sineTour))
  sineTourRes <- getProj(sin1000, sineTourFull, "Sine", 1000)
  #sineTourResMelt <- melt(sineTourRes, id=c("t", "name", "size"))
  #save(sineResc, sineTour, sineTourFull, sineTourRes, sineTourResMelt, file = "cache/findsine.rda")
  save(sineResc, sineTour, sineTourFull, sineTourRes, file = "cache/findsine.rda")
} else {
  load("cache/findsine.rda")
}
anchorIdx <- as_tibble(which(attributes(interpolate(sineTour))$new_basis))
sineTourResMelt <-sineTourRes %>%
  mutate(convex = 1-convex) %>%
  rename("1-convex"=convex) %>%
  rowwise() %>%
  mutate(holes = rescaleHoles(holes)) %>%
  select(-cmass) %>%
  gather(variable, value, -t, -name, -size) %>%
  mutate(variable = fct_relevel(variable, "holes", "1-convex", "skinny", "stringy", "dcor2d", "splines2d", "MIC", "TIC"))

ggplot(sineTourResMelt, aes(x=t, y=value)) +
  geom_line(mapping=aes(color=(variable=="splines2d"))) + 
  facet_wrap(~variable, ncol=1, scales = "free_y") +
  scale_colour_manual(values = c("black", "red")) +
  facet_wrap(~variable, ncol=1, strip.position = "right") +
  geom_vline(data=anchorIdx, mapping=aes(xintercept=value), color="blue", alpha=0.3) +
  guides(color=FALSE) +
  ylim(c(0,1)) + xlab("Number of projections") + ylab("PPI value")
```


### Spiral detection

The spiral is the most challenging structure to detect because it has a small squint angle [@posse95a], especially as the ratio of noise to structure dimensions increases. This is explored using optimisation method 2 to scout the space for approximate maxima. The skinny scagnostic index is used because it was observed (Figure \ref{fig:wIntermediate}) to be sensitive to this structure, although the noisiness of the index might be problematic. The stringy appears to be more sensitive to the spiral, but it has a much smaller squint angle. 

The search is conducted for $p=4,5,6$ which would correspond to 2, 3 and 4 noise dimensions respectively. In addition we examine the distance between planes, using a Frobenius norm, as defined by Equation 2 of @BCAH05, and available in the ```proj_dist``` function in the tourr package, to compare searches across dimensions. The distance between planes is related to squint angle, how far away from the ideal projection can the structure be glimpsed. We estimate the squint angle depending on the number of noise dimensions in the appendix. In order for the optimizer to find the spiral, the distance between planes would need to be smaller than the squint angle. Figure \ref{fig:findspiral} summarizes the results. When $p=4$ the scouting method effectively finds the spiral. Plot (a) shows the side-by-side boxplots of pairwise distances between planes examined during the optimization, for $p=4,5,6$. These are on average smaller for the lower dimension, and gradually increase as dimension increases. This is an indication of the extra computation needed to brute force find the spiral as noise dimensions increase. Plot (b) shows the distance of the plane in each iteration of the optimisation to the ideal plane, where it can be seen that only when $p=4$ does it converge to the ideal. Its likely that expanding the search space should result in uncovering the spiral in higher dimensions, which however requires tuning of the stopping conditions and long run times.


```{r findspiral, out.width="0.9\\textwidth", fig.cap="Guided tour optimising the skinny index for the Sprial dataset with 1000 datapoints, with p = 4, 5, 6. The left plot shows the distribution of pairwise distances between planes obtained via the guided tour, the right shows the evolution of distance to the ideal plane as the index is being optimised.", results="hide", fig.width=7, fig.height=2.5}

distanceDist <- function(planes, nn=F){
  #nn could be used to turn on only distance to nearest neighbour?
  planes <- as.list(planes)
  maxI <- length(planes)
  distL <- numeric(choose(maxI, 2))
  i <- 1
  idx <- 1
  while(i<maxI+1){
    j <- i+1
    while(j<maxI+1){
      cDist <- proj_dist(planes[[i]], planes[[j]])
      distL[idx] <- cDist
      j <- j+1
      idx <- idx+1
    }
    i <- i+1
  }
  return(distL)
}

distanceToSp <- function(planes, specialPlane){
  planes <- as.list(planes)
  maxI <- length(planes)
  distL <- numeric(maxI)
  i <- 1
  while(i<maxI+1){
    cDist <- proj_dist(planes[[i]], specialPlane)
    distL[i] <- cDist
    i <- i+1
  }
  return(distL)
  }

if(!file.exists("cache/findspiral.rda")){
  distDf <- tibble(d=numeric(), distance=numeric())
  distToSp <- tibble(d=numeric(), distance=numeric(), t=numeric())

  maxBases <- 100
#  maxBases <- 1000
  fViewL <- list()
  allPlanes <- list()
  i <- 1
  for(d in c(4,5,6)){
  #d = 6
    set.seed(58958)
    specialPlane <- matrix(c(rep(0,d-2),1,0,rep(0,d-1),1),ncol=2)
    spiralD <- spiral1000 %>%
      purrr::when(d<6 ~ select(., -V4), ~ .) %>%
      purrr::when(d<5 ~ select(., -V3), ~ .)
    spiralTour <- save_history(as.matrix(spiralD),
                               guided_tour(scagIndex("Skinny"), 
                                  search_f = tourr:::search_better,
                                  max.tries = 5000, 
                                  #max.tries = 50000, 
                                  cooling = 1, alpha = pi),
                              max_bases = maxBases)
    #if(d==4){maxBases <- min(maxBases, length(spiralTour))}
    nBases <- length(spiralTour)
    distDf <- rbind(distDf, tibble(d=d, distance=distanceDist(spiralTour)))
    distToSp <- rbind(distToSp, tibble(d=d, distance=distanceToSp(spiralTour, specialPlane), t=1:nBases))
    fView <- as_tibble(as.matrix(spiralD) %*% as.list(spiralTour)[[nBases]])
    fViewL[[i]] <- ggplot(fView, aes(V1, V2)) + geom_point()
    allPlanes[[i]] <- spiralTour
    i <- i+1
  }
  save(distDf, distToSp, fViewL, allPlanes, file = "cache/findspiral.rda")
} else {
  load("cache/findspiral.rda")
}

distDf <- distDf %>%
  mutate(p=d) %>%
  select(-d)

distToSp <- distToSp %>%
  mutate(p=d) %>%
  select(-d)

p1 <- ggplot(distDf, aes(group=p, y=distance, x=p)) +
  geom_boxplot() +
  scale_x_continuous(breaks = c(4, 5, 6)) + ggtitle("(a)")
p2 <- ggplot(distToSp, aes(color=as.factor(p),x =t, y=distance)) +
  geom_point() +
  labs(y = "Distance to special view", color = "p") + ggtitle("(b)")


fViewL[[1]] <- fViewL[[1]] + xlab("PP1") + ylab("PP2")
fViewL[[2]] <- fViewL[[2]] + xlab("PP1") + ylab("PP2")
fViewL[[3]] <- fViewL[[3]] + xlab("PP1") + ylab("PP2")

#grid.arrange(p1, p2, fViewL[[1]], fViewL[[2]], fViewL[[3]], layout_matrix = rbind(c(1,2,2),c(3,4,5)))
grid.arrange(p1, p2, layout_matrix = rbind(c(1,2,2)))
```


## Rotational invariance or not
\label{sec:rot}

Rotational invariance is examined using the sine data ($x_5$-$x_6$), computing PPI for different rotations within the 2D plane, parameterized by angle. Results are shown in Figure \ref{fig:rotationDep}. Several indexes are invariant, holes, convex and MIC, because their value is constant around rotations. The dcor2d, splines2d and TIC index are clearly not rotationally invariant because the value changes depending on the rotation. The scagnostics indexes are approximately rotationally invariant, but particularly the skinny index has some random variation depending on rotation. 

```{r rotationDep, out.width=".6\\textwidth", fig.cap="PPI for rotations of the sine 1000 data, to examine rotation invariance. Most are close to rotation invariant, except for skinny, dcor2d, splines2d and TIC."}
if(!file.exists("cache/rotationDep.rda")){
  sineM <- as.matrix(select(sin1000, V5, V6))
  sc <- tibble(
      holes=numeric(),
      cmass=numeric(),
      convex=numeric(),
      skinny=numeric(),
      stringy=numeric(),
      dcor2d=numeric(),
      splines2d=numeric(),
      MIC=numeric(),
      TIC=numeric(),
      alpha=numeric()
  )
  for (a in seq(0,2*pi, pi/100)){
    rotM <- matrix(c(cos(a), sin(a), -sin(a), cos(a)), ncol = 2)
    dprj <- sineM %*% rotM
    scagRes <- scagnostics(dprj)
    dcorRes <- dcor2d(dprj[,1], dprj[,2])
    splineRes <- splines2d(dprj[,1], dprj[,2])
    mineRes <- mine(dprj[,1], dprj[,2])
    holesRes <- holes(dprj)
    cmassRes <- cmass(dprj)
    sc <- add_row(sc, holes=holesRes, cmass=cmassRes,
                  convex=scagRes[,"Convex"], skinny=scagRes[,"Skinny"],
                  stringy=scagRes[,"Stringy"], dcor2d=dcorRes,
                  splines2d=splineRes, MIC=mineRes$MIC,
                  TIC=mineRes$TIC/148, alpha=a)
  }
  save(sc, file = "cache/rotationDep.rda")
} else {
  load("cache/rotationDep.rda")
}

scMelt <- sc %>% 
  mutate(convex = 1-convex) %>%
  rename("1-convex"=convex) %>%
  rowwise() %>%
  mutate(holes = rescaleHoles(holes)) %>%
  #rowwise() %>%
  #mutate(cmass = rescaleCmass(cmass)) %>%
  select(-cmass) %>%
  mutate(angle=alpha*360/(2*pi), TIC = TIC) %>%
  select(-alpha) %>%
  gather(PPI, value, -angle) %>%
  mutate(PPI = fct_relevel(PPI, "holes", "1-convex", "skinny", "stringy", "dcor2d", "splines2d", "MIC", "TIC"))

ggplot(scMelt, aes(x=angle, y=value)) +
  geom_line() + 
  ylim(c(-1, 1.1)) +
  facet_wrap(~PPI, ncol = 3) +
  #geom_blank(aes(y = 0)) +
  #geom_blank(aes(y = 1)) +
  coord_polar() +
  xlab("") + ylab("")
```

## Speed
Examining the computing time as a function of sample size we find that scagnostics and splines2d are fast even for large samples, while all other index functions slow rapidly with increasing sample size. Detailed results are shown in Appendix \ref{app:speed}.

## Parameter choices
Some PPIs have a choice of parameters, and the choice can have an effect on function smoothness, and sensitivity to structure. In Appendix \ref{app:param} we examine the dependence of the scagnostics indexes on the binning, showing that even with small number of bins the indexes are noisy, while they lose ability to see structure. Sensitivity to the number of bins in the MIC index is also examined, showing that tuning the parameter can improve the final result.

## Index enhancement
We identified two potential improvements. First, the issue of noisy index functions may be addressed via smoothing, and we explore different smoothing options for the examples of the skinny and stringy index in Appendix \ref{app:enh}. In addition, rotation dependent indexes may be enhanced by redefining them in a rotation invariant way.

## Summary

Our results can be summarized by evaluating and comparing the advantages and disadvantages of each index function according to the criteria presented above. Such an overview is given in Table \ref{tab:summary}, listing if the criteria is fully met (\checkmark), there are some shortcomings ($\cdot$) or failure ($\times$).
\textcolor{red}{Notice that the established holes index does not appear in the summary.}
We find that none of the indexes considered meet all criteria, and in particular rotation invariance is often not fulfilled. In addition the limited flexibility of most indexes highlights the importance of index selection in the projection pursuit setup. Table \ref{tab:summary} further suggests that there is much room for the improvement of index functions detecting unusual association between model parameters.

\begin{table}
\begin{center}
\caption{Summary of findings, showing to what extend the considered new index functions pass the criteria for a good PPI. ``\checkmark" symbols good behavior, ``$\cdot$" symbols some issues while ``$\times$" symbols failure on the corresponding criteria. Each index has particular strengths and drawbacks and selection must be guided by the considered example, see text for details.}
\label{tab:summary}
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
Index & smooth & squintability & flexible & rotation invariant & speed \\
\hline
convex & $\cdot$ & $\cdot$ & $\cdot$ & \checkmark & \checkmark \\
skinny & $\cdot$ & $\cdot$ & $\cdot$ & $\times$ & \checkmark \\
stringy & $\times$ & $\times$ & $\cdot$ & $\cdot$ & \checkmark \\
\hline
splines2D & \checkmark & \checkmark & $\cdot$ & $\times$ & \checkmark \\
dcor2D & \checkmark & \checkmark & $\cdot$ & $\times$ & $\cdot$ \\
\hline
MIC & $\cdot$ & \checkmark  & \checkmark & $\cdot$ & $\cdot$ \\
TIC & $\cdot$ & \checkmark  & \checkmark & $\cdot$ & $\cdot$ \\
\hline
\end{tabular}
\end{center}
\end{table}




# Application to physics examples
\label{sec:phys}



This section describes the application of these projection pursuit indices to find two-dimensional structure in two multidimensional gravitational waves problems.

The first example contains 2538 posterior samples obtained by fitting source parameters to the observed gravitational wave signal GW170817 from a neutron star merger [@PhysRevLett119161101]. Data has been downloaded from @ligoData. The fitting procedures are described in detail in @Abbott2018exr. We consider six parameters of physical interest (6-D) with some known relationships. Projection pursuit is used to find the known relationships. 

The second example contains data generated from a simulation study of a binary black hole (BBH) merger event, as described in @Smith:2016qas. There are 12 parameters (12-D), with multiple nuisance parameters. Projection pursuit uncovers new relationships between parameters. 

## Neutron star merger

Figure \ref{fig:neutronStarSPLOM} in the Appendix shows the scatterplot matrix (with transparency) of the six parameters. (In astrophysics, scatterplot matrices are often called "corner plots" [@corner].) The diagonal shows a univariate density plot of each parameter, and the upper triangle of cells displays the correlation between variables. From this it can be seen that m1 and m2 are strongly, and slightly, nonlinearly associated. Between the other variables we observe some linear association (R1, R2), some nonlinear association (L1, L2, R1, R2),  heteroskedastic variance in most variables and some bimodality (R1, L1, L2, m1, m2). 

The model describes a neutron star merger and contains 6 free parameters, with each neutron star described by its mass $m$ (m1, m2) and radius $R$ (R1, R2), and a so-called tidal deformability parameter $\Lambda$ (L1, L2) which is a function of the mass and radius, approximately proportional to $(m/R)^{-5}$. 

### Data pre-pocessing

Because m1 and m2 are very strongly associated, m2 is dropped before doing PP. This relationship is obvious from the scatterplots of pairs of variables and does not need to be re-discovered by PP. 

All variables are scaled to range between 0 and 1. The purpose is that range differences in individual variables should not affect the detection  of relationships between multiple variables. Standardising the range will still leave differences between the standard deviations of the variables, and for this problem this is preferred. Differences in the standard deviations can be important for keeping the non-linear relationships visible to PP.  

### Applying PP

With only five parameters, a reasonable start is to examine the 5D space using a grand tour. This quickly shows  the strong nonlinear relationships between the parameters. PP is then used to extract these relationships. The best index for this sort of problem is the splines2d, and it is fast to compute. 

Figure \ref{fig:nsePlotOrig} shows the optimal projection found by splines2d, a reconstructed view obtained by manually combining parameters, and a plot of the known relationship between parameters. 




```{r neutronStarEq,  results="hide"}
nsD <- read_csv("data/samples.csv") 
nsM <- nsD %>%
  select(-m2) %>% # remove m2 to avoid finding well known correlation
  rescale() # rescaling, this returns a matrix
if(!file.exists("cache/neutronStarEq.rda")){
  set.seed(2018)
  nseTour <- save_history(nsM, guided_tour(splineIndex()))
  nseTourFull <- as.list(interpolate(nseTour))
  save(nseTour, nseTourFull, file = "cache/neutronStarEq.rda")
} else {
  load("cache/neutronStarEq.rda")
}
iLast <- length(nseTourFull)
fProj <- nseTourFull[[iLast]]
dProj <- as_tibble(nsM %*% fProj)
colnames(fProj) <- c("PP1", "PP2")
colnames(dProj) <- c("PP1", "PP2")
fProj <- as_tibble(fProj) %>%
  add_column(label=colnames(nsM))
```

```{r axesDrawing}
#select cntrx, cntry for placement
#sclx and scly should be 20% of overall range
getCircle <- function(cntrx, cntry, sclx, scly){
  theta <- seq(0, 2 * pi, length = 50)
  circ <- tibble(x=cos(theta), y=sin(theta))
  circ <- circ %>% 
    mutate(x=x*sclx+cntrx, y=y*scly+cntry)
}
getAxes <- function(fProj, cntrx, cntry, sclx, scly){
  x1 <- rep(cntrx, length(fProj$PP1))
  y1 <- rep(cntry, length(fProj[,1]))
  x2 <- fProj$PP1*sclx+cntrx
  y2 <- fProj$PP2*scly+cntry
  lab <- fProj$label
  axes <- tibble(x1=x1, y1=y1, x2=x2, y2=y2, label=lab)
}
```

```{r nsePlotOrig, fig.cap="Comparison of guided tour final view (left), approximation based on original parameters (middle) and expected relation based on analysis setup (right)."}
p1 <- ggplot(dProj, aes(PP1, PP2)) + geom_point(alpha = 0.05) + theme(aspect.ratio=1) + 
  geom_path(data=getCircle(0,0.6,0.32,0.22), aes(x=x, y=y), color="grey") + 
  xlim(-1.1, 0.5) + ylim(-0.2, 0.9) +
  geom_segment(data=getAxes(fProj, 0,0.6,0.32,0.22), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj, 0,0.6,0.32,0.22), aes(x=x2, y=y2, label=label), size=2.5)
p2 <- ggplot(nsD, aes(R1-2*pi*m1, L1)) + geom_point(alpha = 0.05) + theme(aspect.ratio=1)
p3 <- ggplot(nsD, aes(R1/m1, L1)) + geom_point(alpha = 0.05) + theme(aspect.ratio=1)
grid.arrange(p1, p2, p3, ncol=3) 
```

To further investigate relationships between parameters, $L1$ is removed and PP with the splines2D is applied to the remaining four parameters. The dependence of $L2$ on the mass and radius of the lighter neutron star, is revealed (Figure \ref{fig:nseRemL1} left plot). A manual reconstruction shows this is a relationship between L2, R1, R2 and m1 (middle plot), but it is effectively the known relationship between L2, R2 and m2 (right plot) -- m2 is latently in the relationship though m1. 

```{r nseRemL1, fig.cap="Removing L1 and optimise again of the remaining parameters, where m2 remains removed from the set. Because of parameter correlations we can recover clear description of L2 as a function of the other parameters, despite m2 missing."}
nsM2 <- nsD %>%
  select(-m2, -L1) %>% # remove m2 to avoid finding well known correlation
  rescale()
if(!file.exists("cache/neutronRemL1.rda")){
  set.seed(2018)
  nseTour2 <- save_history(nsM2, guided_tour(splineIndex()))
  save(nseTour2, file = "cache/neutronRemL1.rda")
} else{
  load("cache/neutronRemL1.rda")
}
tL <- as.list(nseTour2)
iLast <- length(tL)
fProj <- tL[[iLast]]
dProj <- as_tibble(nsM2 %*% fProj)
colnames(fProj) <- c("PP1", "PP2")
colnames(dProj) <- c("PP1", "PP2")
fProj <- as_tibble(fProj) %>%
  add_column(label=colnames(nsM2))
p1 <- ggplot(as_tibble(dProj), aes(PP1, PP2))+geom_point(alpha=0.1)+ theme(aspect.ratio=1) + 
  geom_path(data=getCircle(0.5,0.6,0.3,0.18), aes(x=x, y=y), color="grey") + 
  xlim(0, 1.5) + ylim(-0.1, 0.8) +
  geom_segment(data=getAxes(fProj, 0.5,0.6,0.3,0.18), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj, 0.5,0.6,0.3,0.18), aes(x=x2, y=y2, label=label), size=2.5)
p2 <- ggplot(as_tibble(nsM2), aes(m1+R1+1.5*R2, L2)) + geom_point(alpha=0.1)+ theme(aspect.ratio=1)
p3 <- ggplot(nsD, aes(R2/m2, L2))+ geom_point(alpha=0.1)+ theme(aspect.ratio=1)
grid.arrange(p1, p2, p3, ncol=3)
```


## Black hole simulation

This data contains posterior samples from simulation from a model describing a binary black hole (BBH) merger event. There are twelve model parameters. Flat priors are used for most model parameters. 

Figure \ref{fig:bbhSimulation} in the Appendix shows a scatterplot matrix, of nine of the twelve parameters. (Parameter m2 is not shown because it is strongly linearly associated with m1, phi$\_$jl and psi are not shown because they are uniform, and not associated with other parameters.) Among the nine plotted parameters, strong nonlinear relationships can be seen between the parameters ra, dec and time. The first two describe the position of the event in the sky, and time is the merging time (in GPS units). Because of the elliptical relationship between dec and time, the TIC index is used for PP, even though it is slow to compute. Between the other parameters, the main structure seen is multimodality and some skewness. These patterns are representative of the likelihood function, since most priors are flat, or built to capture growth with volume rather than distance. 


### Data pre-processing

The analysis is conducted on 11 of the twelve parameters. One variable is removed, m2, because it is so strongly associated with m1. All parameters are scaled into the range 0 to 1. 

### Applying PP

#### Exploring 11D with all PP indexes

All seven PP indexes are applied to the data. Figure \ref{fig:bbhGuided} showing the projections that maximize three of the indexes. TIC and splines2d indexes identify very similar projections, that are based on the three parameters, dec, time and ra. This is to be expected based on the pairwise scatterplots. On the other hand, the 1-convex index finds a very different view, but this is because the optimization doesn't adequately reach a maximum for this index. 


```{r bbhGuided, results="hide", fig.cap="Projections corresponding to the maxima of three indices: TIC, splines2D and 1-convex. Projections a, b found by TIC and splines2d are very similar, and involve the same three parameters, ra, dec and time. The 1-convex index finds a very different view.", fig.height = 3.2, dev = "png", dpi=300}
bbhD <- read_csv("data/posterior_samples.csv")
bbhM <- rescale(select(bbhD,-m2, -chi_eff))
if(!file.exists("cache/bbhGuidedTIC.rda")){
  set.seed(2018)
  bbhTour1 <- save_history(bbhM, guided_tour(mineIndex("TIC")))
  bbhTourFull1 <- as.list(interpolate(bbhTour1))
  save(bbhTour1, bbhTourFull1, file = "cache/bbhGuidedTIC.rda")
} else {
  load("cache/bbhGuidedTIC.rda")
}
if(!file.exists("cache/bbhGuidedSpline.rda")){
  set.seed(2018)
  bbhTour2 <- save_history(bbhM, guided_tour(splineIndex()))
  bbhTourFull2 <- as.list(interpolate(bbhTour2))
  save(bbhTour2, bbhTourFull2, file = "cache/bbhGuidedSpline.rda")
} else {
  load("cache/bbhGuidedSpline.rda")
}
if(!file.exists("cache/bbhGuidedConvex.rda")){
  set.seed(2018)
  bbhTour3 <- save_history(bbhM, guided_tour(invConvexIndex()))
  bbhTourFull3 <- as.list(interpolate(bbhTour3))
  save(bbhTour3, bbhTourFull3, file = "cache/bbhGuidedConvex.rda")
} else {
  load("cache/bbhGuidedConvex.rda")
}

iLast <- length(bbhTourFull1)
fProj1 <- bbhTourFull1[[iLast]]
dProj1 <- as_tibble(bbhM %*% fProj1)
colnames(fProj1) <- c("PP1", "PP2")
colnames(dProj1) <- c("PP1", "PP2")
fProj1 <- as_tibble(fProj1) %>%
  add_column(label=colnames(bbhM))
p1 <- ggplot(dProj1, aes(PP1,PP2)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1) + 
  geom_path(data=getCircle(0.4,0.5,0.26,0.24), aes(x=x, y=y), color="grey") + 
  xlim(0.1, 1.4) + ylim(-0.3, 0.9) +
  geom_segment(data=getAxes(fProj1, 0.4,0.5,0.26,0.24), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj1, 0.4,0.5,0.26,0.24), aes(x=x2, y=y2, label=label), size=2.5) + ggtitle("a. TIC: 779.46")
iLast <- length(bbhTourFull2)
fProj2 <- bbhTourFull2[[iLast]]
dProj2 <- as_tibble(bbhM %*% fProj2)
colnames(fProj2) <- c("PP1", "PP2")
colnames(dProj2) <- c("PP1", "PP2")
fProj2 <- as_tibble(fProj2) %>%
  add_column(label=colnames(bbhM))
p2 <- ggplot(dProj2, aes(PP1,PP2)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1) + 
  geom_path(data=getCircle(0.3,-1,0.24,0.22), aes(x=x, y=y), color="grey") + 
  xlim(-0.1, 1.1) + ylim(-1.3, -0.2) +
  geom_segment(data=getAxes(fProj2,0.3,-1,0.24,0.22), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj2, 0.3,-1,0.24,0.22), aes(x=x2, y=y2, label=label), size=2.5) + ggtitle("b. splines2D: 0.97")
iLast <- length(bbhTourFull3)
fProj3 <- bbhTourFull3[[iLast]]
dProj3 <- as_tibble(bbhM %*% fProj3)
colnames(fProj3) <- c("PP1", "PP2")
colnames(dProj3) <- c("PP1", "PP2")
fProj3 <- as_tibble(fProj3) %>%
  add_column(label=colnames(bbhM))
p3 <- ggplot(dProj3, aes(PP1,PP2)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1) + 
  geom_path(data=getCircle(0.75, 1, 0.3, 0.28), aes(x=x, y=y), color="grey") + 
  xlim(-0.2, 1.3) + ylim(-0.1, 1.3) +
  geom_segment(data=getAxes(fProj3,0.75, 1, 0.3, 0.28), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj3, 0.75, 1, 0.3, 0.28), aes(x=x2, y=y2, label=label), size=2.5) + ggtitle("c. 1-convex: 0.50")
grid.arrange(p1, p2, p3, ncol=3) 
```


```{r indexTableBBH, eval=FALSE}
getIdxComp <- function(dProj, n){
  ticI <- mine(dProj$PP1, dProj$PP2)$TIC
  splineI <- splines2d(dProj$PP1, dProj$PP2)
  invConvI <- 1-scagnostics(as.matrix(dProj))[,"Convex"]
  return(tibble(TIC=ticI, splines2D=splineI, invConv=invConvI, nView=n))
}
idxT <- tibble(TIC=numeric(),
               splines2D=numeric(),
               invConv=numeric(),
               nView=numeric())
idxT <- rbind(idxT, getIdxComp(dProj1, 1),
      getIdxComp(dProj2, 2),
      getIdxComp(dProj3, 3))
colnames(idxT) <- c("TIC", "splines2D", "1-convex", "Projection")
knitr::kable(idxT,  caption = "Matrix of index values, for all three indices and all three final projections. \\label{tab:indexTableBBH}", digits=2) 
```


#### Exploring reduced space

The variables time, dec and ra are dropped from the data, and PP is applied to the remaining 8D space. Figure \ref{fig:bbhGuided2} shows the projections which maximize the TIC, splines2D and 1-convex indices. The results provide similar information as already learned from the scatterplot matrix (Figure \ref{fig:bbhSimulation}). The parameters chi$\_$tot and chi$\_$p are linearly related (TIC maxima), and theta$\_$jn has a bimodal distribution yielding the figure 8 shape found by the splines2d index. The 1-convex index finds nothing interesting. 


```{r bbhGuided2, results="hide", fig.cap="Projections of the reduced 8D space corresponding to the maxima of three indices: TIC, splines2d and 1-convex.", fig.height = 3.2, dev = "png", dpi=300}
bbhM2 <- rescale(select(bbhD,-m2, -chi_eff, -time, -dec, -ra))
if(!file.exists("cache/bbhGuidedTIC2.rda")){
  set.seed(2018)
  bbhTour12 <- save_history(bbhM2, guided_tour(mineIndex("TIC")))
  bbhTourFull12 <- as.list(interpolate(bbhTour12))
  save(bbhTour12, bbhTourFull12, file = "cache/bbhGuidedTIC2.rda")
} else {
  load("cache/bbhGuidedTIC2.rda")
}
if(!file.exists("cache/bbhGuidedSpline2.rda")){
  set.seed(2018)
  bbhTour22 <- save_history(bbhM2, guided_tour(splineIndex()))
  bbhTourFull22 <- as.list(interpolate(bbhTour22))
  save(bbhTour22, bbhTourFull22, file = "cache/bbhGuidedSpline2.rda")
} else {
  load("cache/bbhGuidedSpline2.rda")
}
if(!file.exists("cache/bbhGuidedConvex2.rda")){
  set.seed(2018)
  bbhTour32 <- save_history(bbhM2, guided_tour(invConvexIndex()))
  bbhTourFull32 <- as.list(interpolate(bbhTour32))
  save(bbhTour32, bbhTourFull32, file = "cache/bbhGuidedConvex2.rda")
} else {
  load("cache/bbhGuidedConvex2.rda")
}

iLast <- length(bbhTourFull12)
fProj1 <- bbhTourFull12[[iLast]]
dProj <- as_tibble(bbhM2 %*% fProj1)
colnames(fProj1) <- c("PP1", "PP2")
colnames(dProj) <- c("PP1", "PP2")
fProj1 <- as_tibble(fProj1) %>%
  add_column(label=colnames(bbhM2))
iv <- mine(dProj$PP1,dProj$PP2)["TIC"]
p1 <- ggplot(dProj, aes(PP1,PP2)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1) + 
  geom_path(data=getCircle(1, 0, 0.34, 0.25), aes(x=x, y=y), color="grey") + 
  xlim(-0.2, 1.5) + ylim(-0.25, 1) +
  geom_segment(data=getAxes(fProj1,1, 0, 0.34, 0.25), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj1, 1, 0, 0.34, 0.25), aes(x=x2, y=y2, label=label), size=2.5) +
  ggtitle(paste0("a, TIC: ", toString(format(iv, digits=2))))
iLast <- length(bbhTourFull22)
fProj2 <- bbhTourFull22[[iLast]]
dProj <- as_tibble(bbhM2 %*% fProj2)
colnames(fProj2) <- c("PP1", "PP2")
colnames(dProj) <- c("PP1", "PP2")
fProj2 <- as_tibble(fProj2) %>%
  add_column(label=colnames(bbhM2))
iv <- splines2d(dProj$PP1,dProj$PP2)
p2 <- ggplot(dProj, aes(PP1,PP2)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1)+ 
  geom_path(data=getCircle(0.75, 0, 0.25, 0.24), aes(x=x, y=y), color="grey") + 
  xlim(-0.25, 1) + ylim(-0.9, 0.3) +
  geom_segment(data=getAxes(fProj2, 0.75, 0, 0.25, 0.24), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj2, 0.75, 0, 0.25, 0.24), aes(x=x2, y=y2, label=label), size=2.5) +
  ggtitle(paste0("b, splines2d: ", toString(format(iv, digits=2))))
iLast <- length(bbhTourFull32)
fProj3 <- bbhTourFull32[[iLast]]
dProj <- as_tibble(bbhM2 %*% fProj3)
colnames(fProj3) <- c("PP1", "PP2")
colnames(dProj) <- c("PP1", "PP2")
fProj3 <- as_tibble(fProj3) %>%
  add_column(label=colnames(bbhM2))
iv <- 1-scagnostics(as.matrix(dProj))[,"Convex"]
p3 <- ggplot(dProj, aes(PP1,PP2)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1)+ 
  geom_path(data=getCircle(0, 1.25, 0.32, 0.32), aes(x=x, y=y), color="grey") + 
  xlim(-0.4, 1.2) + ylim(0, 1.6) +
  geom_segment(data=getAxes(fProj3, 0, 1.25, 0.32, 0.32), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj3, 0, 1.25, 0.32, 0.32), aes(x=x2, y=y2, label=label), size=2.5) +
  ggtitle(paste0("c, 1-convex: ", toString(format(iv, digits=2))))
grid.arrange(p1, p2, p3, ncol=3) 
```

#### Effect of random starts, and subsets used

The initial conditions for the optimization, and the subset of variables used, can have a large effect on the projections returned. We illustrate this using only the splines2d index, and find that there is one more association that can be learned that was masked earlier.

Figure \ref{fig:bbhGuided3} shows six maxima obtained by different starts, for two types of parameters: first, spin related parameters (i.e. alpha, theta\_jn, chi\_tot and chi\_p), and second position related parameters (i.e. ra, dec and distance). Four of the six (a-d) are almost identical, but not interesting projections. Projection f has the highest PP index value but it is primarily the view seen in the bivariate plot of dec and ra.  While none of these projections are particularly interesting on their own, moving between them can be revealing.

Choosing a different subset of variables reveals something new. The subspace of m1, ra, chi\_tot, alpha, distance, dec produces a more refined view of Figure \ref{fig:bbhGuided3} projection f. When alpha contributes in contrast to dec, the relationship between the points is almost perfectly on a curve. This is shown in Figure \ref{fig:constructedExample}. Manually reconstructing the optimal projection (left plot) can be done by differencing the two parameters, in their original units. This highlights the importance of improved optimisation, that would use tiny final steps to polish the view to a finer optimal projection and possibly remove noise induced by small contributions of many variables.

```{r bbhGuided3, results="hide", fig.cap=paste("Final views identified in the dataset considering the seven dimensional parameter space (alpha, theta\\_jn, chi\\_tot, chi\\_p, ra, dec, distance), differing only by randomly selected starting plane."), dev = "png", dpi=300}
bbhM3 <- rescale(select(bbhD, alpha, theta_jn, chi_tot, chi_p, ra, dec, distance))
getResWithSeed <- function(s){
  set.seed(s)
  startM <- orthonormalise(matrix(runif(14),ncol = 2))
  tourRes <- save_history(bbhM3, guided_tour(splineIndex()))
}

if(!file.exists("cache/bbhGuidedSpline3.rda")){
  set.seed(2018)
  seedVals <- sample(1:10000, 6)
  bbhRes1 <- getResWithSeed(seedVals[1])
  bbhRes2 <- getResWithSeed(seedVals[2])
  bbhRes3 <- getResWithSeed(seedVals[3])
  bbhRes4 <- getResWithSeed(seedVals[4])
  bbhRes5 <- getResWithSeed(seedVals[5])
  bbhRes6 <- getResWithSeed(seedVals[6])
  save(bbhRes1, bbhRes2, bbhRes3, bbhRes4, bbhRes5, bbhRes6, file = "cache/bbhGuidedSpline3.rda")
} else {
  load("cache/bbhGuidedSpline3.rda")
}
resList <- list(as.list(bbhRes1), as.list(bbhRes2), as.list(bbhRes3),
                as.list(bbhRes4), as.list(bbhRes5), as.list(bbhRes6))
pList <- list()
idxV <- NULL
i <- 1
xmins <- c(-0.5,-0.5,-0.4,-0.9,-1,0.25)
xmaxs <- c(0.75,0.75,0.8,0.4,0.25,1.5)
ymins <- c(-0.8,-0.8,-0.7,-0.8,-1.2,-0.6)
ymaxs <- c(0.7,0.6,0.7,0.7,0.,0.9)
xscales <- c(0.25,0.25,0.24,0.26,0.25,0.25)
yscales <- c(0.3,0.28,0.28,0.3,0.24,0.3)
xcents <- c(0.25,-0.25,-0.1,0.1,-0.75,1.25)
ycents <- c(0.4,-0.4,-0.4,-0.4,-0.75,0.5)
titleL <- c("a: ","b: ","c: ","d: ","f: ","e: ")
for (r in resList){
  iLast <- length(r)
  fProj <- r[[iLast]]
  dProj <- as_tibble(bbhM3 %*% fProj)
  colnames(fProj) <- c("PP1", "PP2")
  colnames(dProj) <- c("PP1", "PP2")
  fProj <- as_tibble(fProj) %>%
    add_column(label=colnames(bbhM3))
  idxV <- splines2d(dProj$PP1, dProj$PP2)
  pList[[i]] <- ggplot(dProj, aes(PP1,PP2)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1)+ 
  geom_path(data=getCircle(xcents[i],ycents[i],xscales[i],yscales[i]), aes(x=x, y=y), color="grey") + 
  xlim(xmins[i], xmaxs[i]) + ylim(ymins[i], ymaxs[i]) +
  geom_segment(data=getAxes(fProj, xcents[i],ycents[i],xscales[i],yscales[i]), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj, xcents[i],ycents[i],xscales[i],yscales[i]), aes(x=x2, y=y2, label=label), size=2.5) +
    ggtitle(paste0(titleL[i], toString(format(idxV, digits=2))))
  i <- i+1
}
grid.arrange(pList[[1]], pList[[2]], pList[[3]],pList[[4]], pList[[6]], pList[[5]], ncol=3)
```

```{r eval=FALSE}
m3 <- matrix(c(1,0,0,0,1,0,0,0,1,0,0,0,1,0),ncol=2)
m4 <- matrix(c(1,1,1,0,0,0,0,0,1,1,0,0,0,0),ncol=2)
planeL <- list(m3, m4)
li <- 3
for(i in c(1, 3, 6, 5)){
  r <- resList[[i]]
  iLast <- length(r)
  fProj <- r[[iLast]]
  planeL[[li]] <- fProj
  li <- li+1
}
tP <- tourr::planned_tour(planeL[3:6]) # only need dummy planes when using history tour
dPoints <- attributes(r)$data
quartz()
animate_xy(dPoints, tP, pch=".")
```



```{r constructedExample, results="hide", fig.cap="Manual reconstruction of an optimal projection (left), constructed by differencing alpha from dec in the original units against ra (middle), compared with the two main variables (right).", fig.height = 3.2, dev = "png", dpi=300}
bbhC <- rescale(select(bbhD, m1, ra, chi_tot, alpha, distance, dec))
if(!file.exists("cache/constructedExample.rda")){
  set.seed(1999)
  tC <- save_history(bbhC, guided_tour(splineIndex()))
  save(tC, file = "cache/constructedExample.rda")
} else {
  load("cache/constructedExample.rda")
}
iL <- length(as.list(tC))
dProj <- bbhC %*% as.list(tC)[[iL]]
fProj <- as.list(tC)[[iL]]
colnames(fProj) <- c("PP1", "PP2")
colnames(dProj) <- c("PP1", "PP2")
fProj <- as_tibble(fProj) %>%
  add_column(label=colnames(bbhC))
p1 <- ggplot(as_tibble(dProj), aes(PP1, PP2))+geom_point(alpha=0.02) + theme(aspect.ratio=1)+ 
  geom_path(data=getCircle(-0.7, 0.6, 0.2, 0.24), aes(x=x, y=y), color="grey") + 
  xlim(-0.9, 0.1) + ylim(-0.1, 1.1) +
  geom_segment(data=getAxes(fProj, -0.7, 0.6, 0.2, 0.24), aes(x=x1, xend=x2, y=y1, yend=y2)) +
  geom_text(data=getAxes(fProj, -0.7, 0.6, 0.2, 0.24), aes(x=x2, y=y2, label=label), size=2.5)
p2 <- ggplot(as_tibble(bbhD),aes(dec-alpha, ra)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1)
p3 <- ggplot(as_tibble(bbhD),aes(dec, ra)) + geom_point(alpha = 0.02) + theme(aspect.ratio=1)
grid.arrange(p1, p2, p3, ncol=3)
```

## Application guide

Applying projection pursuit to new datasets can be done using the guided tour available in the `tourr` package. The necessary steps are:

1. Scaling and standardization of the data
2. Index function selection and if necessary formatting according to the guided tour requirements, i.e. a function taking matrix input and returning the index value
3. Calling the guided tour with the data and index function via:
    + for exploration this can be done via the `tourr::animate` function
    + for recording the results `tourr::save_history` should be used
4. Exploring how the results depend on choices made (index function, starting planes, optimisation method, reducing dimensionality)

<!--

# Applications to collections of time series 

This could be another example.

```{r eval=FALSE}
music <- read_csv("data/tigs_music.csv")
music <- apply(music, 2, function(x) (x-mean(x))/sd(x))
musicTour <- save_history(music,
                         guided_tour(mineIndex("TIC"), 
                            search_f = tourr:::search_better,
                            cooling=1, alpha = 0.5, max.tries = 5000))
musicTour <- save_history(music,
                         guided_tour(dcorIndex(), 
                            search_f = tourr:::search_better,
                            cooling=1, alpha = 0.5, max.tries = 5000))
musicTourFull <- as.list(interpolate(musicTour))
iLast <- length(musicTourFull)
fProj <- musicTourFull[[iLast]]
dProj <- as_tibble(as.matrix(music) %*% fProj)
ggplot(dProj, aes(V1,V2)) + geom_point() + theme(aspect.ratio=1)
fullRes <- getProj(as.matrix(music), musicTourFull, "TIC", 100)
fullResMelt <- melt(fullRes, id=c("t", "name", "size"))
ggplot(fullResMelt, aes(x=t, y=value)) +
  geom_line(aes(color=factor(size))) + 
  facet_wrap(variable~name, ncol=3, scales = "free_y", labeller = label_wrap_gen(multi_line=FALSE)) +
  guides(color=FALSE)
```

-->

# Discussion

<!--
Reminder what the paper is about
summarise main findings
Future plans
-->

The motivation for this work was to discover dependencies between estimated parameters in multiple model fits in physics problems. This paper shows how projection pursuit with the new indexes can help address this problem. The results are encouraging, showing large potential for discovering unanticipated relations between multiple variables.

All of the indexes fall short against some aspect of the ideal properties of smoothness, squintability, flexibility, rotation invariance and speed. The paper describes how these properties can be assessed using tour methodology. Some potential fixes for the indexes are discussed but there is scope for further developing the new indexes.
\textcolor{red}{We recommend to use the spinebil [XXX REF] package when developing new indexes. It includes the functionalities needed to reproduce the assessments presented in this paper. While the current focus is on two-dimensional index functions, indexes in the tourr package apply to arbitrary projection dimension, and the methodology introduced here could be applied to the assessment of index functions where $d>2$.}

The work also reveals inadequacies in the tour optimization algorithm, that may benefit from newly developed techniques and software tools. Exploring this area would help improve the guided tours.
\textcolor{red}{As new optimization techniques become available, adapting these to the guided tour would extend the technique to a broader range of problems. The current recommended approach is to first reduce the dimensionality, for example by using PCA, taking care to preserve nonlinear structure, prior to applying PP.}

\textcolor{red}{To use the existing index functions on real-world datasets we recommend to either use the tourr package directly, or if interaction is required to call the guided tour via the graphical interface available in the galahr [XXX Ref] package, superseding the now archived tourrGui [@tourrGui]. Both packages contain examples to show how the guided tour can be used with different index functions.}

# Supplementary material

This article was created with R Markdown [@rmarkdown], the code for the paper is available at [XXX].
The functions for testing new index functions as presented in this work are implemented in the R package spinebil [XXX].
The R package galahr [XXX] provides a graphical interface to the tourr package allowing for interactive exploration using the guided tour.
Additional information in the appendix is XXX

# Acknowledgments {-}
The authors gratefully acknowledge the support of the Australian Research Council.
We thank Rory Smith for help with the gravitational wave examples, and German Valencia for useful comments.
This article was created with knitr [@knitr], R Markdown [@rmarkdown] and bookdown [@bookdown] with embedded code.

\appendix

# Appendix {-} 

# Re-scaling of holes index

Holes and cmass indexes are derived from $I_0^N$ of [@CBC93]. As noted in proposition 1 of that paper the index takes local maxima for the minimum and maximum of $a_0$ which are achieved by central hole and central mass distributions respectively. @Cook:2007:IDG:1557227 then gives explicit index functions defined for sphered data (zero mean, identity variance-covariance matrix). They are defined such that each one is maximized for central holes or central mass type distributions, with maximum=1, and cmass=1-holes. It follows that for either index both large and small values signal deviation from the normal distribution, and given a normal distribution we expect to find "average" index values rather than values close to zero.

We can estimate the values found for normal distribution by comparing values of $a_{00}$ of Sec 7.1 in [@CBC93]. The maximum value is $1/(2\pi)$ found for cmass type distributions, the minimum is $1/(2\pi e)$ found for hole type distributions. Evaluating for normal distributions gives $1/(4\pi)$, rescaling such that the index values range from 0 to 1 then puts the value for normal distributions at approximately $0.2$. This is consistent with the results we found, i.e. for normal distributions the cmass index is about $0.2$, and the holes index (=1-cmass) is about $0.8$.

We therefore rescale as follows: first have cut-off at the respective value for the normal distribution, i.e. any value below 0.2 (0.8) is set to zero for cmass (holes) index, and we rescale the remaining range to be between zero and one.

# Estimating the squint angle of the spiral

We estimate the squint angle of the spiral (for p = 4, 5, 6) as follows. First pick a random starting plane and generate a tour path from the starting plane to the ideal plane containing the spiral. Using skinny as the reference index we fix a lower index value that is attributed to indicate squintability at $0.6$, and we move along the tour path towards the ideal plane until this value is reached. The distance between the thus identified plane and the ideal plane is used as an estimate of the squint angle in this direction. Since this will strongly depend on the random starting plane, i.e. the considered direction, we repeat the estimation 100 times and present the results in the form of a box plot in Figure \ref{fig:squintAngle}. The result shows a large drop in squint angle when going from p = 4 to higher dimensions, and generally a large spread of squint angles depending on the direction.

```{r squintAngle, out.width="0.5\\textwidth", fig.cap="Estimated squint angles for the Spiral dataset with 1000 datapoints, with p = 4, 5, 6, containing estimates evaluated for 100 randomly selected directions each.", results="hide"}

squintAngleEstimat <- function(data, indexF, cutoff, structurePlane, n = 100, stepSize = 0.01){
  # data = numerical input with p > 2 dimensions
  # indexF = the index function used to estimate the squint angle
  # cutoff = lower bound on the index value to be considered structured (i.e. all lower index values are outside the squint angle)
  # structuredPlane = projection matrix onto plane containing the 2-d structure
  # n = number of random starting directions over which the squint angle estimate is averaged
  # stepSize = accuracy, step size determines where the index is evaluated to find the first plane above cutoff
  data <- as.matrix(data) # make sure data is in matrix format
  angles <- numeric(length = n) # collecting all individual estimates
  i <- 1
  p <- ncol(data)
  while(i <= n){
    # first generate random direction, make sure it is not too close to structure plane
    dist <- 0.
    while(dist < 0.1){
      rBasis <- tourr::basis_random(p)
      dist <- tourr::proj_dist(rBasis, structurePlane)
    }
    # now interpolate from rBasis to structure plane with selected step size
    # since planned tour ignores first two entries, generate some random planes to be ignored
    notUsed1 <- tourr::basis_random(p)
    notUsed2 <- tourr::basis_random(p)
    tourHist <- save_history(data,tour_path=planned_tour(list(notUsed1, notUsed2, rBasis, structurePlane)))
    allBases <- as.list(interpolate(tourHist, angle = stepSize))
    cIndex <- 0.
    j <- 1
    while(cIndex < cutoff){
      cProj <- data %*% allBases[[j]]
      cIndex <- indexF(cProj)
      j <- j+1
    }
    cDist <- tourr::proj_dist(allBases[[j]], structurePlane)
    angles[i] <- cDist
    i <- i+1
  }
  return(angles)
}

if(!file.exists("cache/squintAngle.rda")){
  allAngles <- tibble(d=numeric(), angle=numeric())
  for(d in c(4,5,6)){
    set.seed(58958)
    specialPlane <- matrix(c(rep(0,d-2),1,0,rep(0,d-1),1),ncol=2)
    spiralD <- spiral1000 %>%
      purrr::when(d<6 ~ select(., -V4), ~ .) %>%
      purrr::when(d<5 ~ select(., -V3), ~ .)
    cAngles <- squintAngleEstimat(spiralD, scagIndex("Skinny"), 0.6, specialPlane)
    allAngles <- bind_rows(allAngles, tibble(d=d, angle=cAngles))
  }
  save(allAngles, file = "cache/squintAngle.rda")
} else {
  load("cache/squintAngle.rda")
}

allAngles <- rename(allAngles, p=d)

ggplot(allAngles, aes(p, angle, group=p)) + geom_boxplot()
```


# Computational performance {#app:speed}
Computational time is important for using the PPIs with the guided tour, online. Figure \ref{fig:timer} summarizes performance for each PPI. For simplicity, data with sample sizes ranging from 100-10000 are drawn from a 6-d solid sphere, using the geozoo package [@geozoo].  The time to compute the PPIs over 100 interpolated grand tour projections is recorded. The scagnostics PPI are computed as a bundle, since this is the code base, and that major computational constraint is common to all the scagnostics. There are two versions of the MIC and TIC algorithm, labelled MINE and MINE E, the second being a newer algorithm which improves their computational performance. 

The results are interesting. The scagnostic indexes and splines2d are very fast regardless of sample size. MIC, TIC (both versions) and dcor2d slow rapidly as sample size increases.


```{r getTimer}

mineE <- function(x,y){
  return(mine(x=x, y=y, est = "mic_e"))
}


timeThis <- function(d, t, idx, pmax, n, idxName){ #d=data matrix, t=interpolated tour path, idx=index function, pmax=max number of projections, n=sample size, idxName=str name of idx funciton
    i <- 1
    dfTimer = data.frame( t= numeric(), i=numeric(), n = numeric(), name=character())
    for(pMatrix in t){
      if(i>pmax) break
      tic.clearlog()
      tic() #start timer
      dProj <- d %*% pMatrix
      sgnst <- idx(dProj[,1],dProj[,2])
      toc(log=TRUE,quiet=TRUE)
      scTd <- unlist(tic.log(format=FALSE))["toc.elapsed"]-unlist(tic.log(format=FALSE))["tic.elapsed"]
      dfTimer <- add_row(dfTimer, t=scTd, i=i, n= n, name=idxName)
      i = i+1
    }
    return(dfTimer)
}

```


```{r timer, fig.cap="Computational perfoamce for PPIs, using sample sizes 100-10000. Colour indicates the PPI. Because the scagnostics calculation is bundled together, the values are the same for all these indexes, and they are really fast to compute. MINE includes the MIC and TIC indexes, and MINE E are computationally more efficient algorithms for these. These, along with dcor2D, are slower with larger sample sizes.", out.width=".6\\textwidth"}
if(!file.exists("cache/timer.rda")){
  set.seed(2018)
  grandTour100 <- save_history(sphereData(6,100), grand_tour(2), max=4) %>%
    interpolate() %>%
    as.list()

  sizeL <- c(10, 100, 500, 1000, 5000, 10000)
  t <- 1
  dfTimer <- NULL
  for(sampleSize in sizeL){
    set.seed(sampleSize + 11) # new seed for each sample size
    if(sampleSize == 0) sampleSize = 10 # smallest considered sample has 10 points
    thisMatrix <-  sphereData(6, sampleSize) %>% rescale()
    scagT <- timeThis(thisMatrix, grandTour100, scagnostics.default, 100, sampleSize, "scagnostics")
    dcorT <- timeThis(thisMatrix, grandTour100, dcor2d, 100, sampleSize, "dcor2D")
    splineT <- timeThis(thisMatrix, grandTour100, splines2d, 100, sampleSize, "splines2D")
    mineT <- timeThis(thisMatrix, grandTour100, mine, 100, sampleSize, "MINE")
    mineeT <- timeThis(thisMatrix, grandTour100, mineE, 100, sampleSize, "MINE E")
    dfTimerC <- list(scagT, dcorT, splineT, mineT,mineeT) %>%
      reduce(rbind)
    dfTimer <- rbind(dfTimer, dfTimerC)
    t <-  t+1
  }
  save(dfTimer, file = "cache/timer.rda")
} else {
  load("cache/timer.rda")
}

timerMeans <- dfTimer %>%
  group_by(name, n) %>%
  summarise(t=mean(t))

ggplot(dfTimer, aes(x = n, y = t)) + 
  geom_point(alpha=0.1, aes(color=name, shape=name)) +
  geom_point(data=timerMeans, aes(color=name, shape=name)) +
  geom_line(data=timerMeans, aes(linetype=name, color=name)) +
  scale_x_log10(limits=c(90,10100)) +
#  scale_y_log10(limits=c(0.00001,1)) + 
  labs(x = "Sample Size", y = "Time [s]", color = "Index family", 
       linetype = "Index family", shape = "Index family") + 
  scale_colour_brewer(palette="Dark2")
```


# Effect of parameter choice in index value {#app:param}
Some parameters must be provided for some PPIs. This can be advantageous, allowing the index to more flexibly work for different types of structure, controlling trade-offs between noise and fine structure detection, and affecting computing time and precision.

- Binning:
    - Scagnostics: the number of bins can be controlled by the user, note however that internally the implementation will reduce the number of bins if too many non-empty bins are found (more than 250).
    - MINE: the maximum number of bins considered is fixed by the user as a function of the number of data points. The default is chosen as a trade-off between resolution and noise dependence, but it may be tuned based on requirements dictated by specific datasets. Apart from sensitivity to noise computing time may also be a consideration here.
- Spline knots: for the splines2d measure we need to fix the number of knots. By default it is fixed to be 10 (or lower if appropriate based on the data values). In our examples we find the number to be appropriate to identify functional dependence while rejecting noise, but some distributions may require tuning of this parameter.

<!--### Effect of binning in scagnostics -->

The bins argument for the scagnostics might be reasonably expected to affect the smoothness of the index: a small number of bins should provide a smooth index function, but may affect its ability to detect fine structure. Figure \ref{fig:spiralScagBinning} examines this. Scagnostics PPIs are computed for the spiral1000 data on a tour path between $x_1$-$x_2$ to $x_5$-$x_6$, for number of bins equal to 10, 20, 50. The interesting observation to make is that even with small bin size the functions are all relatively noisy. The problem with the small bin size is that the spiral becomes invisible to the PPI. 


```{r spiralScagBinning, fig.cap="Comparing the traces of the three scagnostics indices when changing the binning via the bins parameter set to 10, 20 and 50 in this example.", out.width=".7\\textwidth"}
getScagComp <- function(df, tPath){
  sc <- tibble(
    convex10=numeric(),
    skinny10=numeric(),
    stringy10=numeric(),
    convex20=numeric(),
    skinny20=numeric(),
    stringy20=numeric(),
    convex50=numeric(),
    skinny50=numeric(),
    stringy50=numeric(),
    t=numeric())
  n <- length(tPath)
  for (i in 1:n) {
    dprj <- as.matrix(df) %*% tPath[[i]]
    scagRes10 <- scagnostics.default(dprj[,1], dprj[,2], bins=10)$s
    scagRes20 <- scagnostics.default(dprj[,1], dprj[,2], bins=20)$s
    scagRes50 <- scagnostics.default(dprj[,1], dprj[,2], bins=50)$s
    sc <- add_row(sc,
                  convex10=scagRes10["Convex"], skinny10=scagRes10["Skinny"],
                  stringy10=scagRes10["Stringy"],
                  convex20=scagRes20["Convex"], skinny20=scagRes20["Skinny"],
                  stringy20=scagRes20["Stringy"],
                  convex50=scagRes50["Convex"], skinny50=scagRes50["Skinny"],
                  stringy50=scagRes50["Stringy"],
                  t=i)
  }
  
  return(sc)
}
if(!file.exists("cache/spiralScagBinning.rda")){
  scagBinningDf <- getScagComp(spiral1000, t2full)
  scagMelt <- gather(scagBinningDf, variable, value, -t) %>%
    mutate(nbin = as.numeric(str_sub(variable, start = -2))) %>%
    mutate(idx = str_sub(variable, end = -3))
  save(scagBinningDf, scagMelt, file = "cache/spiralScagBinning.rda")
} else {
  load("cache/spiralScagBinning.rda")
}
ggplot(scagMelt, aes(x=t, y=value)) +
  geom_line(aes(color=factor(nbin))) + 
  facet_wrap(~idx, ncol=1, scales = "free_y", labeller = label_wrap_gen(multi_line=FALSE)) +
  scale_colour_discrete("bins") + xlab("Number of projections") + 
  ylab("PPI value")

```

## Binning sensitivity of MIC index
To examine the sensitivity of binning in the MIC PPI, the classic RANDU data [@Marsaglia68], available in R, is used. Binning is defined by $\delta$, where $B(n) = n^{\delta}$. Figure \ref{fig:randuEx} shows the best projection, index value and computing time obtained when optimizing the MIC index with values $\delta = 0.6, 0.7, 0.8$. With small $\delta$, less bins, the structure isn't visible, and with larger $\delta$ the structure is confounded with noise. It does appear that this parameter affects the performance of the MIC index.


```{r randuEx, results="hide", fig.cap="Best projection obtained by optimising the MIC index on the RANDU data, using different number of bins, defined by $\\delta$. The smaller the value the fewer bins.  Above each plot is written the value of $\\delta$, time required to optimize (seconds) and the MIC index value. The best $\\delta = 0.7$, and the result indicates that this parameter does affect MIC performance."}
if(!file.exists("cache/randuEx.rda")){
  pL <- list()
  i <- 1
  for (alpha in c( 0.6, 0.7, 0.8)){
    set.seed(556677)
    tic.clearlog()
    tic() #start timer
    tP <- save_history(randu, guided_tour(mineIndexAlpha("MIC", alpha)),max_bases = 100000)
    toc(log=TRUE,quiet=TRUE)
    optT <- unlist(tic.log(format=FALSE))["toc.elapsed"]-unlist(tic.log(format=FALSE))["tic.elapsed"]
    imax <- length(as.list(tP))
    fV <- as_tibble(as.matrix(randu) %*% as.list(tP)[[imax]])
    colnames(fV) <- c("PP1", "PP2")
    idxV <- mine(fV$PP1, fV$PP2, alpha = alpha)[["MIC"]]
    pL[[i]] <- ggplot(fV, aes(PP1,PP2)) + geom_point() + theme(aspect.ratio=1) + 
      ggtitle(paste(alpha, toString(format(optT, digits=2)), toString(format(idxV, digits=2)), sep = ", "))
    i <- i+1
  }
  save(pL, file = "cache/randuEx.rda")
} else {
  load("cache/randuEx.rda")
}
grid.arrange(pL[[1]], pL[[2]], pL[[3]], ncol=3)
```



# Ways to refine the PPIs {#app:enh}

The biggest issues revealed by the investigation into the new PPIs are a lack of smoothness, particularly for the scagnostics indexes, and the rotation invariance of Grimm's indexes. To fix the smoothness of an index function, it is possible to calculate the PPI for a small neighbourhood of projections and average the value, or alternatively average the PPI for several jittered projections. This is investigated in Fig. \ref{fig:spiralScagSmoothing}. Rotation invariance is more difficult to fix, but an alternative tour interpolation method could be useful. The geodesic interpolation transitions between planes, and it ignores the basis defining the plane, creating a problem with rotation invariant indices. Alternative interpolations based on Givens or Householder rotations could be implemented to transition between bases, which should alleviate the need for rotationally invariant indices. 


Two different methods are considered for smoothing the index values:

* Jittering points: using the jitter function we move each point by a random amount drawn from a uniform distribution between $\pm \beta$.
* Jittering angles: using the tourr implementation we can draw a random plane and move some small amount $\epsilon$ in that direction.

The mean value from a sample of projections is recorded as the PPI value. This could be robsitufied by dropping the most extreme values. 

This is particularly interesting for the scagnostics indexes skinny and stringy which we found to be most noisy among the indexes considered. Figure \ref{fig:spiralScagSmoothing} studies the potential of these two smoothing approaches, using the tour path between noise variables of the spiral1000 dataset and different $\epsilon$ and $\beta$ values. Both methods appear to be promising in smoothing the function. Because the scagnostics are fast to compute, either of these methods is feasible. For this example we have smoothed over 10 randomly selected jittered views, computing time increases linearly with the number of randomly jittered views, as this is mostly determined by the time needed to evaluate the scagnostics indexes which is done separately for each view.


```{r spiralScagSmoothing, fig.cap="Comparing the traces of the scagnostics indexes skinny and stringy when smoothing the index values, either by averaging over the index value after jittering the projection by some angle $\\epsilon$ (full line) or after jittering the projected datapoints with some amount $\\beta$ (dashed line). For comparison the red line in the background shows the trace without any smoothing applied."}

jitterScagnostics <-function(proj, d, alpha){
  newProj <- tourr:::basis_nearby(proj, alpha = alpha, method = "geodesic")
  newD <- d %*% newProj
  return(as.vector(scagnostics.default(newD[,1],newD[,2])$s))
}

jitterPointsScagnostics <-function(projData, alpha){
  newD <- jitter(projData, amount=alpha)
  return(as.vector(scagnostics.default(newD[,1],newD[,2])$s))
}


getSgnMean <- function(proj, d, alpha, method){
  dProj <- d %*% proj
  orig <- as.vector(scagnostics.default(dProj[,1],dProj[,2])$s)
  if(method == "jitterAngle"){
    sgnVec <- replicate(10, jitterScagnostics(proj, d, alpha))
  } else if (method=="jitterPoints"){
    sgnVec <- replicate(10, jitterPointsScagnostics(dProj, alpha))
  }
  return(rowMeans(cbind(orig, sgnVec)))
}

getScagSmooth <- function(df, tPath){
  sc <- tibble(
    convex=numeric(),
    skinny=numeric(),
    stringy=numeric(),
    t=numeric(),
    method=character(),
    alpha=numeric())
  n <- length(tPath)
  for (method in c("jitterAngle", "jitterPoints")){
    for (alpha in c(0.01, 0.05, 0.1)){
      for (i in 1:n) {
        scagMean <- getSgnMean(tPath[[i]], as.matrix(df), alpha, method)
        convex <- scagMean[6]
        skinny <- scagMean[7]
        stringy <- scagMean[8]
        sc <- sc %>% add_row(convex=convex, skinny=skinny, stringy=stringy,
                             t=i, method=method, alpha=alpha)
      }
    }
  }
  
  return(sc)
}

if(!file.exists("cache/spiralScagSmoothing.rda")){
  scagSmooth <- getScagSmooth(spiral1000, as.list(t1full))
  scagSmoothMelt <- gather(scagSmooth, variable, value, -t, -method, -alpha)
  save(scagSmooth, scagSmoothMelt, file = "cache/spiralScagSmoothing.rda")
} else {
  load("cache/spiralScagSmoothing.rda")
}

#getting non-smoothed result
load("cache/V1V2toV3V4.rda")
noSmoothing <- fullRes %>%
  filter(size==1000) %>%
  filter(name=="spiral") %>%
  select(skinny, stringy, t) %>%
  gather(variable, value, -t)

scagSmoothMelt <- scagSmoothMelt %>%
  filter(variable != "convex") %>%
  mutate(method = factor(method, levels = c("jitterAngle", "jitterPoints")))
ggplot(scagSmoothMelt, aes(x=t, y=value)) +
  geom_line(data=noSmoothing, color="red", alpha=0.5) +
  geom_line(aes(linetype=factor(method))) + 
  theme(legend.position="none") +
  ylim(0,1) +
  facet_grid(alpha~variable) +
  xlab("Sequence of projections (t)") +
  ylab("PPI value")

```



# Additional Figures

## Final projection of pipe guided tour
Figure \ref{fig:testpipe} shows the projection returned during the scouting phase (left) and the refinement phase (right). It was important to start the method 3 optimizer at the best projection returned during the scouting phase, to smoothly converge more closely to the ideal projection.

```{r testpipe,  fig.height=4, fig.width=8, out.width = "0.8\\textwidth",  fig.cap="Projections returned by TIC optimisation: by the scouting phase (left) and refined by  optimisation method 3 (right), starting from the scouting phase projection."}
iLast <- length(pipeTourFull)
fProj <- pipeTourFull[[iLast]]
dProj <- as_tibble(pipeResc %*% fProj)
p1 <- ggplot(dProj, aes(V1,V2)) + geom_point() + theme(aspect.ratio=1) +
  xlab("PP1") + ylab("PP2")
iLast <- length(pipeTourFull2)
fProj <- pipeTourFull2[[iLast]]
dProj <- as_tibble(pipeResc %*% fProj)
p2 <- ggplot(dProj, aes(V1,V2)) + geom_point() + theme(aspect.ratio=1) +
  xlab("PP1") + ylab("PP2")
grid.arrange(p1, p2, ncol=2)
```

## Dataset overview scatter plot matrices

Figures \ref{fig:neutronStarSPLOM} and \ref{fig:bbhSimulation} show the scatter plot matrices of the gravitational wave datasets considered, see Section \ref{sec:phys} for details.

```{r neutronStarSPLOM, fig.height=8, fig.width=8, fig.cap="Scatter plot matrix of the neutron star dataset, darker regions represent higher marginalised posterior densities."}
ggpairs(nsD, lower=list(continuous = wrap("points", alpha = 0.05)))
```

```{r bbhSimulation, fig.height=8, fig.width=8, dev = "png", dpi=300, fig.cap="Scatter plot matrix showing most of the variables included in the BBH dataset. Strong correlation between the parameters time, dec and ra can be observed."}
bbhDsmall <- select(bbhD, -phi_jl, -m2, -psi, -chi_eff)
ggpairs(bbhDsmall, lower=list(continuous = wrap("points", alpha = 0.02)))
```

# References {-}